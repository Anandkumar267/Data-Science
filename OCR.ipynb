{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2BLyTu34Vjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990cf02c-3839-4343-c344-a2e61261a497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [00:02<00:00, 221MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "dps = 5\n",
        "n_sequences = 10000\n",
        "output_path = './dataset'\n",
        "\n",
        "emnist_dataset = torchvision.datasets.EMNIST('./EMNIST', split='digits', train=True, download=True)\n",
        "dataset_sequences = []\n",
        "dataset_label = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_dataset.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDkEZ_kkSBS9",
        "outputId": "385fa119-be1e-425a-dd3a-24ef81fe4c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "i = random.randint(0, len(emnist_dataset.data))\n",
        "plt.imshow( emnist_dataset.data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "8uUGiRBXSDO3",
        "outputId": "0f9ea1ad-8fc9-4c61-8012-d509f65636ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7891afb625d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Images need to undergo transformation as 90 degree anticlockwise rotation and  "
      ],
      "metadata": {
        "id": "E6tNU7JGTh9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_sequences):\n",
        "  random_indices = np.random.randint(len(emnist_dataset.data), size=(dps,) )\n",
        "  random_digits_data = emnist_dataset.data[random_indices]\n",
        "  transformed_random_digits_images= []\n",
        "  for img in random_digits_data:\n",
        "    temp = torchvision.transforms.ToPILImage()(img)\n",
        "    temp = torchvision.transforms.functional.rotate(temp, -90, fill=(0,))\n",
        "    temp = torchvision.transforms.functional.hflip(temp)\n",
        "    # random tilting of images\n",
        "    temp = torchvision.transforms.RandomAffine(degrees=10, translate=(0.1, 0.2), scale=(0.8,1.))(temp)\n",
        "    temp = torchvision.transforms.ToTensor()(temp).numpy()\n",
        "    transformed_random_digits_images.append(temp)\n",
        "\n",
        "  random_digit_images = np.array(transformed_random_digits_images)\n",
        "  random_digit_label = emnist_dataset.targets[random_indices]\n",
        "\n",
        "  random_sequence = np.hstack(random_digit_images.reshape(dps, 28, 28))\n",
        "  random_label = np.hstack(random_digit_label.reshape(dps, 1))\n",
        "\n",
        "  dataset_sequences.append(random_sequence / 255)\n",
        "  dataset_label.append(random_label)\n"
      ],
      "metadata": {
        "id": "491qgj0dSXCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "\n",
        "dataset_data = np.array(dataset_sequences)\n",
        "dataset_label = np.array(dataset_label)\n",
        "np.save(os.path.join(output_path, 'sequence.npy'), dataset_sequences)\n",
        "np.save(os.path.join(output_path, 'label.npy'), dataset_label)"
      ],
      "metadata": {
        "id": "13WATztbZcod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "import numpy as np\n",
        "data_path = output_path + \"/sequence.npy\"\n",
        "label_path = output_path + \"/label.npy\"\n",
        "\n",
        "data = np.load(data_path)\n",
        "label = np.load(label_path)\n",
        "data  = torch.Tensor(data)\n",
        "label= torch.IntTensor(label)\n",
        "sequence_dataset = TensorDataset(data, label)\n",
        "train_set, test_set = torch.utils.data.random_split(sequence_dataset, [int(len(label)*0.8), int(len(label)*0.2)])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "7wcGDlFDZmHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_, y_ in train_loader:\n",
        "  for j in range(len(x_)):\n",
        "    plt.imshow(x_[j], cmap='grey')\n",
        "    plt.show()\n",
        "\n",
        "    break\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "DyFLDFEM0P3j",
        "outputId": "66e27b36-e161-4d75-ab11-97cec3128c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7T1kYXB0DkWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.num_classes = 10 + 1\n",
        "        self.image_H = 28\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3,3))\n",
        "        self.in1 = nn.InstanceNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3))\n",
        "        self.in2 = nn.InstanceNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2)\n",
        "        self.in3 = nn.InstanceNorm2d(32)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3,3))\n",
        "        self.in4 = nn.InstanceNorm2d(64)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=(3,3))\n",
        "        self.in5 = nn.InstanceNorm2d(64)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(64, 64, kernel_size=(3,3), stride=2)\n",
        "        self.in6 = nn.InstanceNorm2d(64)\n",
        "\n",
        "        self.postconv_height= 3\n",
        "        self.postconv_width= 31\n",
        "\n",
        "        self.gru_input_size = self.postconv_height*64\n",
        "        self.gru_hidden_size = 128\n",
        "        self.gru_num_layers = 2\n",
        "        self.gru_h = None\n",
        "        self.gru_cell = None\n",
        "        self.gru  = nn.GRU(self.gru_input_size, self.gru_hidden_size, self.gru_num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.fc = nn.Linear(self.gru_hidden_size*2, self.num_classes)\n",
        "    def forward(self,x):\n",
        "        batch_size = x.shape[0]\n",
        "        out = self.conv1(x)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in3(out)\n",
        "\n",
        "        out = self.conv4(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in4(out)\n",
        "\n",
        "        out = self.conv5(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in5(out)\n",
        "\n",
        "        out = self.conv6(out)\n",
        "        out = F.leaky_relu(out)\n",
        "        out = self.in6(out)\n",
        "\n",
        "        out = out.permute(0, 3, 2, 1)\n",
        "\n",
        "        out = out.reshape(batch_size, -1, self.gru_input_size)\n",
        "        self.gru_h = self.gru_h.to(device)\n",
        "        out, self.gru_h = self.gru(out, self.gru_h)\n",
        "        self.gru_h = self.gru_h.detach()\n",
        "\n",
        "        out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
        "        return out\n",
        "    def reset_hidden(self, batch_size):\n",
        "        h = torch.zeros(self.gru_num_layers*2, batch_size, self.gru_hidden_size)\n",
        "        self.gru_h = Variable(h)\n",
        "        self.gru_h.to(device)\n",
        "\n",
        "crnn = CRNN().to(device)\n",
        "criterion = nn.CTCLoss(blank=10, reduction='mean', zero_infinity=True)\n",
        "optimizer = torch.optim.Adam(crnn.parameters(), lr=0.001)\n",
        "\n",
        "BLANK_LABEL = 10\n",
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "u9RJ2j6M1yrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "\n",
        "def train():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch_idx, (x_train , y_train)  in enumerate(train_loader):\n",
        "        batch_size = x_train.shape[0]\n",
        "        crnn.reset_hidden(batch_size)\n",
        "        x_train = x_train.to(device)\n",
        "        y_train = y_train.to(device)\n",
        "        x_train = x_train.view(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = crnn(x_train)\n",
        "        y_pred = y_pred.permute(1,0,2)\n",
        "\n",
        "        input_lengths= torch.IntTensor(batch_size).fill_(crnn.postconv_width)\n",
        "        target_lengths = torch.IntTensor([len(b) for b in y_train])\n",
        "\n",
        "        loss = criterion(y_pred,y_train, input_lengths, target_lengths)\n",
        "\n",
        "        total_loss += loss.cpu()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, max_index = torch.max(y_pred, 2)\n",
        "        for i in range(batch_size):\n",
        "            raw_prediction = list(max_index[:,i])\n",
        "\n",
        "            prediction = torch.IntTensor([c for c , _ in groupby(raw_prediction)  if c!=BLANK_LABEL]).to(device)\n",
        "            if (len(prediction) == len(y_train[i]) and torch.all(prediction.eq(y_train[i]))):\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "        num_batches += 1\n",
        "    ratio = correct/total\n",
        "    print(\"Train correct: \", correct, \"total: \", total, \"ratio: \", ratio)\n",
        "    return total_loss/num_batches, ratio"
      ],
      "metadata": {
        "id": "-F5hi7nVA9JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(EPOCHS):\n",
        "    training_loss = train()\n",
        "\n",
        "    if e == 5:\n",
        "        print(f\"Training Loss {training_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_OfKlguy_YmF",
        "outputId": "ad065204-b0bc-429a-ee01-5350c2dbddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  488 total:  8000 ratio:  0.061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  5568 total:  8000 ratio:  0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  6726 total:  8000 ratio:  0.84075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7052 total:  8000 ratio:  0.8815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7329 total:  8000 ratio:  0.916125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7480 total:  8000 ratio:  0.935\n",
            "Training Loss (tensor(0.0481, grad_fn=<DivBackward0>), 0.935)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7636 total:  8000 ratio:  0.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7792 total:  8000 ratio:  0.974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7648 total:  8000 ratio:  0.956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7766 total:  8000 ratio:  0.97075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7780 total:  8000 ratio:  0.9725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7887 total:  8000 ratio:  0.985875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7701 total:  8000 ratio:  0.962625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7849 total:  8000 ratio:  0.981125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train correct:  7951 total:  8000 ratio:  0.993875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n",
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-32-4285096100.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Loss {training_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-31-3921228772.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_loader:\n",
        "    batch_size = x.shape[0]\n",
        "    crnn.reset_hidden(batch_size)\n",
        "    x_train = x.to(device)\n",
        "    y_train = y.to(device)\n",
        "    x_train = x_train.view(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2])\n",
        "    y_pred = crnn(x_train)\n",
        "    y_pred = y_pred.permute(1,0,2)\n",
        "    print(y_pred.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olSYmk4YIyrY",
        "outputId": "e1ce2be7-d622-486a-a33b-32284b53eb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([31, 64, 11])\n",
            "torch.Size([64, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-3391753102.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  out = torch.stack([F.log_softmax(self.fc(out[i])) for i in range(out.shape[0])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1L1ibAxPTmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}