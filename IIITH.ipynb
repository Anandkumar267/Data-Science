{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfozXjKTiOEH",
        "outputId": "a63aa2a7-2683-4ba6-f11c-c41c77d1a31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/iiit5k-words\n"
          ]
        }
      ],
      "source": [
        " import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"prathmeshzade/iiit5k-words\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C6tEWQsiX3D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "f = os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yyME8YCxZYwO",
        "outputId": "e7051048-c514-4eb6-bca9-10380e579fc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/input/iiit5k-words'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntY0NGqOX9yL"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3rs3-svhqWu"
      },
      "outputs": [],
      "source": [
        "t = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "tar_to_idx = {}\n",
        "idx_to_tar = {}\n",
        "for i, j in enumerate(t):\n",
        "    tar_to_idx[j] = i\n",
        "    idx_to_tar[i] = j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prCacD_hzhff"
      },
      "outputs": [],
      "source": [
        "maxlen = 0\n",
        "d = pd.read_csv(path + '/traindata.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbswvDP_zSem",
        "outputId": "aee6f116-70f3-4ff3-ebdc-388efd49425a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ],
      "source": [
        "for i in d.iloc[:,1]:\n",
        "    if maxlen <len(i):\n",
        "        maxlen = len(i)\n",
        "print(maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGGoxRL1bCXC"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGrHT4S4Xemu"
      },
      "outputs": [],
      "source": [
        "def preprocess(target_size=(64,32), maxlen=36):\n",
        "    images = torch.empty((d.shape[0], 3, target_size[1], target_size[0]), dtype=torch.float32) # Initialize with correct shape\n",
        "    labels = torch.empty((d.shape[0], maxlen), dtype=torch.int32)\n",
        "    label_lengths = []\n",
        "    for i in range(d.shape[0]):\n",
        "        td = Image.open(path+'/IIIT5K-Word_V3.0' + '/IIIT5K/' + d.iloc[i, 0])\n",
        "\n",
        "            # image is wider than target\n",
        "        td = td.resize((target_size[0], target_size[1]))\n",
        "            # image is taller than target\n",
        "\n",
        "\n",
        "        td = keras.preprocessing.image.img_to_array(td)\n",
        "        td = torch.tensor(td).permute(2,0,1) / 255. # Permute dimensions to (Channels, Height, Width)\n",
        "\n",
        "\n",
        "        images[i] = td\n",
        "        temp = []\n",
        "        for a in d.iloc[i, 1]:\n",
        "            temp.append(tar_to_idx[a]+1)\n",
        "        label_lengths.append(len(temp))\n",
        "        if len(temp) <maxlen:\n",
        "            temp.extend([0]*(maxlen-len(temp)))\n",
        "        labels[i] = torch.tensor(temp)\n",
        "\n",
        "\n",
        "    return images, labels, label_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8ujKYLfhLb3"
      },
      "outputs": [],
      "source": [
        "def label_to_text(label):\n",
        "    s= ''\n",
        "\n",
        "    l = label.numpy()\n",
        "    for i in l:\n",
        "        if i==0:\n",
        "            continue\n",
        "        s+=idx_to_tar[int(i-1)]\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16d71ZqspjEn"
      },
      "outputs": [],
      "source": [
        "images,labels, label_lengths = preprocess()\n",
        "dataset = torch.utils.data.TensorDataset(images, labels, torch.tensor(label_lengths))\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16) # Reduced batch size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "wTCHw2aQMZsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(0,2000)\n",
        "plt.imshow(images[i].permute(1,2,0))\n",
        "print(label_to_text(labels[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "n1DGO2DYMeNx",
        "outputId": "07e43db3-f6d0-451f-c6b6-fc3c2167c275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 9 14  4  9  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "INDIA\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, imgH, nc, nclass, nh):\n",
        "        super(CRNN, self).__init__()\n",
        "        # CNN feature extractor\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(nc, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d((2,1), (2,1)),\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1), nn.ReLU(), nn.MaxPool2d((2,1), (2,1)),\n",
        "            nn.Conv2d(512, 512, 2, 1, 0), nn.ReLU()\n",
        "        )\n",
        "        # RNN\n",
        "        self.rnn1 = nn.LSTM(512, nh, bidirectional=True)\n",
        "        self.rnn2 = nn.LSTM(nh*2, nh, bidirectional=True)\n",
        "\n",
        "        self.embedding = nn.Linear(nh*2, nclass)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cnn(x)\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"CNN output height must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "\n",
        "        rnn_out1, _ = self.rnn1(conv)\n",
        "        rnn_out2, _ = self.rnn2(rnn_out1)\n",
        "\n",
        "        output = self.embedding(rnn_out2)\n",
        "        return output"
      ],
      "metadata": {
        "id": "jAz3_naF3ekz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_crnn(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels, label_lengths) in enumerate(dataloader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            label_lengths = label_lengths.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)  # outputs shape: [seq_len, batch, nclass]\n",
        "\n",
        "            # Compute input lengths for CTC (all sequences have the same length here)\n",
        "            input_lengths = torch.full(size=(outputs.size(1),), fill_value=outputs.size(0), dtype=torch.long).to(device)\n",
        "\n",
        "            loss = criterion(outputs.log_softmax(2), labels, input_lengths, label_lengths)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:  # print every 10 mini-batches\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {running_loss / 10:.4f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n"
      ],
      "metadata": {
        "id": "euAbyeh-5X84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ5tRTABe5By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d61b1b-db10-46d2-94a3-be0eb068ef48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [10/125], Loss: 10.1535\n",
            "Epoch [1/100], Step [20/125], Loss: 5.4580\n",
            "Epoch [1/100], Step [30/125], Loss: 4.2115\n",
            "Epoch [1/100], Step [40/125], Loss: 4.0922\n",
            "Epoch [1/100], Step [50/125], Loss: 4.0989\n",
            "Epoch [1/100], Step [60/125], Loss: 3.8365\n",
            "Epoch [1/100], Step [70/125], Loss: 3.7984\n",
            "Epoch [1/100], Step [80/125], Loss: 3.7060\n",
            "Epoch [1/100], Step [90/125], Loss: 3.6351\n",
            "Epoch [1/100], Step [100/125], Loss: 3.6188\n",
            "Epoch [1/100], Step [110/125], Loss: 3.5903\n",
            "Epoch [1/100], Step [120/125], Loss: 3.7545\n",
            "Epoch [2/100], Step [10/125], Loss: 3.8144\n",
            "Epoch [2/100], Step [20/125], Loss: 3.9981\n",
            "Epoch [2/100], Step [30/125], Loss: 3.9223\n",
            "Epoch [2/100], Step [40/125], Loss: 4.0527\n",
            "Epoch [2/100], Step [50/125], Loss: 4.0378\n",
            "Epoch [2/100], Step [60/125], Loss: 3.7527\n",
            "Epoch [2/100], Step [70/125], Loss: 3.7146\n",
            "Epoch [2/100], Step [80/125], Loss: 3.6342\n",
            "Epoch [2/100], Step [90/125], Loss: 3.5099\n",
            "Epoch [2/100], Step [100/125], Loss: 3.5149\n",
            "Epoch [2/100], Step [110/125], Loss: 3.4993\n",
            "Epoch [2/100], Step [120/125], Loss: 3.6172\n",
            "Epoch [3/100], Step [10/125], Loss: 3.6951\n",
            "Epoch [3/100], Step [20/125], Loss: 3.8131\n",
            "Epoch [3/100], Step [30/125], Loss: 3.7699\n",
            "Epoch [3/100], Step [40/125], Loss: 3.7977\n",
            "Epoch [3/100], Step [50/125], Loss: 3.7509\n",
            "Epoch [3/100], Step [60/125], Loss: 3.5968\n",
            "Epoch [3/100], Step [70/125], Loss: 3.5506\n",
            "Epoch [3/100], Step [80/125], Loss: 3.5624\n",
            "Epoch [3/100], Step [90/125], Loss: 3.4360\n",
            "Epoch [3/100], Step [100/125], Loss: 3.4202\n",
            "Epoch [3/100], Step [110/125], Loss: 3.4191\n",
            "Epoch [3/100], Step [120/125], Loss: 3.5123\n",
            "Epoch [4/100], Step [10/125], Loss: 3.6026\n",
            "Epoch [4/100], Step [20/125], Loss: 3.7082\n",
            "Epoch [4/100], Step [30/125], Loss: 3.6456\n",
            "Epoch [4/100], Step [40/125], Loss: 3.6106\n",
            "Epoch [4/100], Step [50/125], Loss: 3.6254\n",
            "Epoch [4/100], Step [60/125], Loss: 3.5404\n",
            "Epoch [4/100], Step [70/125], Loss: 3.4960\n",
            "Epoch [4/100], Step [80/125], Loss: 3.5430\n",
            "Epoch [4/100], Step [90/125], Loss: 3.3983\n",
            "Epoch [4/100], Step [100/125], Loss: 3.3682\n",
            "Epoch [4/100], Step [110/125], Loss: 3.3862\n",
            "Epoch [4/100], Step [120/125], Loss: 3.4623\n",
            "Epoch [5/100], Step [10/125], Loss: 3.5631\n",
            "Epoch [5/100], Step [20/125], Loss: 3.6336\n",
            "Epoch [5/100], Step [30/125], Loss: 3.5765\n",
            "Epoch [5/100], Step [40/125], Loss: 3.4896\n",
            "Epoch [5/100], Step [50/125], Loss: 3.5494\n",
            "Epoch [5/100], Step [60/125], Loss: 3.5168\n",
            "Epoch [5/100], Step [70/125], Loss: 3.4370\n",
            "Epoch [5/100], Step [80/125], Loss: 3.5263\n",
            "Epoch [5/100], Step [90/125], Loss: 3.3612\n",
            "Epoch [5/100], Step [100/125], Loss: 3.3303\n",
            "Epoch [5/100], Step [110/125], Loss: 3.3654\n",
            "Epoch [5/100], Step [120/125], Loss: 3.4336\n",
            "Epoch [6/100], Step [10/125], Loss: 3.5272\n",
            "Epoch [6/100], Step [20/125], Loss: 3.5454\n",
            "Epoch [6/100], Step [30/125], Loss: 3.5030\n",
            "Epoch [6/100], Step [40/125], Loss: 3.3809\n",
            "Epoch [6/100], Step [50/125], Loss: 3.4861\n",
            "Epoch [6/100], Step [60/125], Loss: 3.4742\n",
            "Epoch [6/100], Step [70/125], Loss: 3.3695\n",
            "Epoch [6/100], Step [80/125], Loss: 3.5020\n",
            "Epoch [6/100], Step [90/125], Loss: 3.3202\n",
            "Epoch [6/100], Step [100/125], Loss: 3.2982\n",
            "Epoch [6/100], Step [110/125], Loss: 3.3445\n",
            "Epoch [6/100], Step [120/125], Loss: 3.3952\n",
            "Epoch [7/100], Step [10/125], Loss: 3.5017\n",
            "Epoch [7/100], Step [20/125], Loss: 3.4959\n",
            "Epoch [7/100], Step [30/125], Loss: 3.4598\n",
            "Epoch [7/100], Step [40/125], Loss: 3.2990\n",
            "Epoch [7/100], Step [50/125], Loss: 3.4338\n",
            "Epoch [7/100], Step [60/125], Loss: 3.4398\n",
            "Epoch [7/100], Step [70/125], Loss: 3.3168\n",
            "Epoch [7/100], Step [80/125], Loss: 3.4812\n",
            "Epoch [7/100], Step [90/125], Loss: 3.2935\n",
            "Epoch [7/100], Step [100/125], Loss: 3.2748\n",
            "Epoch [7/100], Step [110/125], Loss: 3.3102\n",
            "Epoch [7/100], Step [120/125], Loss: 3.3551\n",
            "Epoch [8/100], Step [10/125], Loss: 3.4621\n",
            "Epoch [8/100], Step [20/125], Loss: 3.4309\n",
            "Epoch [8/100], Step [30/125], Loss: 3.3826\n",
            "Epoch [8/100], Step [40/125], Loss: 3.2210\n",
            "Epoch [8/100], Step [50/125], Loss: 3.3828\n",
            "Epoch [8/100], Step [60/125], Loss: 3.3975\n",
            "Epoch [8/100], Step [70/125], Loss: 3.2630\n",
            "Epoch [8/100], Step [80/125], Loss: 3.4601\n",
            "Epoch [8/100], Step [90/125], Loss: 3.2720\n",
            "Epoch [8/100], Step [100/125], Loss: 3.2671\n",
            "Epoch [8/100], Step [110/125], Loss: 3.2976\n",
            "Epoch [8/100], Step [120/125], Loss: 3.3350\n",
            "Epoch [9/100], Step [10/125], Loss: 3.4386\n",
            "Epoch [9/100], Step [20/125], Loss: 3.3732\n",
            "Epoch [9/100], Step [30/125], Loss: 3.3349\n",
            "Epoch [9/100], Step [40/125], Loss: 3.1545\n",
            "Epoch [9/100], Step [50/125], Loss: 3.3555\n",
            "Epoch [9/100], Step [60/125], Loss: 3.3746\n",
            "Epoch [9/100], Step [70/125], Loss: 3.2512\n",
            "Epoch [9/100], Step [80/125], Loss: 3.4323\n",
            "Epoch [9/100], Step [90/125], Loss: 3.2261\n",
            "Epoch [9/100], Step [100/125], Loss: 3.2117\n",
            "Epoch [9/100], Step [110/125], Loss: 3.2729\n",
            "Epoch [9/100], Step [120/125], Loss: 3.2836\n",
            "Epoch [10/100], Step [10/125], Loss: 3.3863\n",
            "Epoch [10/100], Step [20/125], Loss: 3.2896\n",
            "Epoch [10/100], Step [30/125], Loss: 3.2804\n",
            "Epoch [10/100], Step [40/125], Loss: 3.0890\n",
            "Epoch [10/100], Step [50/125], Loss: 3.2839\n",
            "Epoch [10/100], Step [60/125], Loss: 3.3225\n",
            "Epoch [10/100], Step [70/125], Loss: 3.1658\n",
            "Epoch [10/100], Step [80/125], Loss: 3.3993\n",
            "Epoch [10/100], Step [90/125], Loss: 3.1901\n",
            "Epoch [10/100], Step [100/125], Loss: 3.2050\n",
            "Epoch [10/100], Step [110/125], Loss: 3.2190\n",
            "Epoch [10/100], Step [120/125], Loss: 3.2078\n",
            "Epoch [11/100], Step [10/125], Loss: 3.3110\n",
            "Epoch [11/100], Step [20/125], Loss: 3.2428\n",
            "Epoch [11/100], Step [30/125], Loss: 3.1930\n",
            "Epoch [11/100], Step [40/125], Loss: 3.0442\n",
            "Epoch [11/100], Step [50/125], Loss: 3.2014\n",
            "Epoch [11/100], Step [60/125], Loss: 3.2723\n",
            "Epoch [11/100], Step [70/125], Loss: 3.0944\n",
            "Epoch [11/100], Step [80/125], Loss: 3.3225\n",
            "Epoch [11/100], Step [90/125], Loss: 3.1677\n",
            "Epoch [11/100], Step [100/125], Loss: 3.1283\n",
            "Epoch [11/100], Step [110/125], Loss: 3.1592\n",
            "Epoch [11/100], Step [120/125], Loss: 3.1353\n",
            "Epoch [12/100], Step [10/125], Loss: 3.2442\n",
            "Epoch [12/100], Step [20/125], Loss: 3.1720\n",
            "Epoch [12/100], Step [30/125], Loss: 3.1371\n",
            "Epoch [12/100], Step [40/125], Loss: 2.9756\n",
            "Epoch [12/100], Step [50/125], Loss: 3.1408\n",
            "Epoch [12/100], Step [60/125], Loss: 3.2327\n",
            "Epoch [12/100], Step [70/125], Loss: 3.0209\n",
            "Epoch [12/100], Step [80/125], Loss: 3.2963\n",
            "Epoch [12/100], Step [90/125], Loss: 3.1230\n",
            "Epoch [12/100], Step [100/125], Loss: 3.1194\n",
            "Epoch [12/100], Step [110/125], Loss: 3.1261\n",
            "Epoch [12/100], Step [120/125], Loss: 3.0900\n",
            "Epoch [13/100], Step [10/125], Loss: 3.1325\n",
            "Epoch [13/100], Step [20/125], Loss: 3.1342\n",
            "Epoch [13/100], Step [30/125], Loss: 3.1044\n",
            "Epoch [13/100], Step [40/125], Loss: 2.9265\n",
            "Epoch [13/100], Step [50/125], Loss: 3.0737\n",
            "Epoch [13/100], Step [60/125], Loss: 3.1833\n",
            "Epoch [13/100], Step [70/125], Loss: 2.9585\n",
            "Epoch [13/100], Step [80/125], Loss: 3.2298\n",
            "Epoch [13/100], Step [90/125], Loss: 3.0752\n",
            "Epoch [13/100], Step [100/125], Loss: 3.0491\n",
            "Epoch [13/100], Step [110/125], Loss: 3.0837\n",
            "Epoch [13/100], Step [120/125], Loss: 2.9794\n",
            "Epoch [14/100], Step [10/125], Loss: 3.0774\n",
            "Epoch [14/100], Step [20/125], Loss: 3.1274\n",
            "Epoch [14/100], Step [30/125], Loss: 3.1336\n",
            "Epoch [14/100], Step [40/125], Loss: 2.9266\n",
            "Epoch [14/100], Step [50/125], Loss: 3.1039\n",
            "Epoch [14/100], Step [60/125], Loss: 3.1345\n",
            "Epoch [14/100], Step [70/125], Loss: 2.9036\n",
            "Epoch [14/100], Step [80/125], Loss: 3.2075\n",
            "Epoch [14/100], Step [90/125], Loss: 3.0574\n",
            "Epoch [14/100], Step [100/125], Loss: 3.0114\n",
            "Epoch [14/100], Step [110/125], Loss: 3.0341\n",
            "Epoch [14/100], Step [120/125], Loss: 2.9235\n",
            "Epoch [15/100], Step [10/125], Loss: 3.0335\n",
            "Epoch [15/100], Step [20/125], Loss: 2.9682\n",
            "Epoch [15/100], Step [30/125], Loss: 2.9656\n",
            "Epoch [15/100], Step [40/125], Loss: 2.8356\n",
            "Epoch [15/100], Step [50/125], Loss: 2.9985\n",
            "Epoch [15/100], Step [60/125], Loss: 3.0628\n",
            "Epoch [15/100], Step [70/125], Loss: 2.8031\n",
            "Epoch [15/100], Step [80/125], Loss: 3.1018\n",
            "Epoch [15/100], Step [90/125], Loss: 2.9642\n",
            "Epoch [15/100], Step [100/125], Loss: 2.9223\n",
            "Epoch [15/100], Step [110/125], Loss: 2.9777\n",
            "Epoch [15/100], Step [120/125], Loss: 2.8183\n",
            "Epoch [16/100], Step [10/125], Loss: 2.9110\n",
            "Epoch [16/100], Step [20/125], Loss: 2.8539\n",
            "Epoch [16/100], Step [30/125], Loss: 2.8312\n",
            "Epoch [16/100], Step [40/125], Loss: 2.7281\n",
            "Epoch [16/100], Step [50/125], Loss: 2.9156\n",
            "Epoch [16/100], Step [60/125], Loss: 3.0833\n",
            "Epoch [16/100], Step [70/125], Loss: 2.8260\n",
            "Epoch [16/100], Step [80/125], Loss: 3.1204\n",
            "Epoch [16/100], Step [90/125], Loss: 2.9155\n",
            "Epoch [16/100], Step [100/125], Loss: 2.8904\n",
            "Epoch [16/100], Step [110/125], Loss: 2.9237\n",
            "Epoch [16/100], Step [120/125], Loss: 2.7809\n",
            "Epoch [17/100], Step [10/125], Loss: 2.8602\n",
            "Epoch [17/100], Step [20/125], Loss: 2.7766\n",
            "Epoch [17/100], Step [30/125], Loss: 2.7673\n",
            "Epoch [17/100], Step [40/125], Loss: 2.6568\n",
            "Epoch [17/100], Step [50/125], Loss: 2.8445\n",
            "Epoch [17/100], Step [60/125], Loss: 2.9694\n",
            "Epoch [17/100], Step [70/125], Loss: 2.7544\n",
            "Epoch [17/100], Step [80/125], Loss: 3.0019\n",
            "Epoch [17/100], Step [90/125], Loss: 2.8301\n",
            "Epoch [17/100], Step [100/125], Loss: 2.8070\n",
            "Epoch [17/100], Step [110/125], Loss: 2.8247\n",
            "Epoch [17/100], Step [120/125], Loss: 2.6936\n",
            "Epoch [18/100], Step [10/125], Loss: 2.7495\n",
            "Epoch [18/100], Step [20/125], Loss: 2.7074\n",
            "Epoch [18/100], Step [30/125], Loss: 2.6793\n",
            "Epoch [18/100], Step [40/125], Loss: 2.6268\n",
            "Epoch [18/100], Step [50/125], Loss: 2.6797\n",
            "Epoch [18/100], Step [60/125], Loss: 2.9312\n",
            "Epoch [18/100], Step [70/125], Loss: 2.6988\n",
            "Epoch [18/100], Step [80/125], Loss: 2.9649\n",
            "Epoch [18/100], Step [90/125], Loss: 2.7415\n",
            "Epoch [18/100], Step [100/125], Loss: 2.7281\n",
            "Epoch [18/100], Step [110/125], Loss: 2.7110\n",
            "Epoch [18/100], Step [120/125], Loss: 2.5888\n",
            "Epoch [19/100], Step [10/125], Loss: 2.6793\n",
            "Epoch [19/100], Step [20/125], Loss: 2.6044\n",
            "Epoch [19/100], Step [30/125], Loss: 2.5591\n",
            "Epoch [19/100], Step [40/125], Loss: 2.5195\n",
            "Epoch [19/100], Step [50/125], Loss: 2.6372\n",
            "Epoch [19/100], Step [60/125], Loss: 2.8003\n",
            "Epoch [19/100], Step [70/125], Loss: 2.5769\n",
            "Epoch [19/100], Step [80/125], Loss: 2.8590\n",
            "Epoch [19/100], Step [90/125], Loss: 2.5907\n",
            "Epoch [19/100], Step [100/125], Loss: 2.6680\n",
            "Epoch [19/100], Step [110/125], Loss: 2.6295\n",
            "Epoch [19/100], Step [120/125], Loss: 2.4904\n",
            "Epoch [20/100], Step [10/125], Loss: 2.6178\n",
            "Epoch [20/100], Step [20/125], Loss: 2.5245\n",
            "Epoch [20/100], Step [30/125], Loss: 2.4810\n",
            "Epoch [20/100], Step [40/125], Loss: 2.4081\n",
            "Epoch [20/100], Step [50/125], Loss: 2.5384\n",
            "Epoch [20/100], Step [60/125], Loss: 2.7531\n",
            "Epoch [20/100], Step [70/125], Loss: 2.4849\n",
            "Epoch [20/100], Step [80/125], Loss: 2.7961\n",
            "Epoch [20/100], Step [90/125], Loss: 2.5333\n",
            "Epoch [20/100], Step [100/125], Loss: 2.6011\n",
            "Epoch [20/100], Step [110/125], Loss: 2.5072\n",
            "Epoch [20/100], Step [120/125], Loss: 2.4252\n",
            "Epoch [21/100], Step [10/125], Loss: 2.4358\n",
            "Epoch [21/100], Step [20/125], Loss: 2.3913\n",
            "Epoch [21/100], Step [30/125], Loss: 2.3549\n",
            "Epoch [21/100], Step [40/125], Loss: 2.2984\n",
            "Epoch [21/100], Step [50/125], Loss: 2.4744\n",
            "Epoch [21/100], Step [60/125], Loss: 2.6189\n",
            "Epoch [21/100], Step [70/125], Loss: 2.4064\n",
            "Epoch [21/100], Step [80/125], Loss: 2.6743\n",
            "Epoch [21/100], Step [90/125], Loss: 2.4366\n",
            "Epoch [21/100], Step [100/125], Loss: 2.4783\n",
            "Epoch [21/100], Step [110/125], Loss: 2.4231\n",
            "Epoch [21/100], Step [120/125], Loss: 2.3655\n",
            "Epoch [22/100], Step [10/125], Loss: 2.3820\n",
            "Epoch [22/100], Step [20/125], Loss: 2.3295\n",
            "Epoch [22/100], Step [30/125], Loss: 2.2627\n",
            "Epoch [22/100], Step [40/125], Loss: 2.2201\n",
            "Epoch [22/100], Step [50/125], Loss: 2.2903\n",
            "Epoch [22/100], Step [60/125], Loss: 2.5219\n",
            "Epoch [22/100], Step [70/125], Loss: 2.3216\n",
            "Epoch [22/100], Step [80/125], Loss: 2.5688\n",
            "Epoch [22/100], Step [90/125], Loss: 2.3197\n",
            "Epoch [22/100], Step [100/125], Loss: 2.3934\n",
            "Epoch [22/100], Step [110/125], Loss: 2.3007\n",
            "Epoch [22/100], Step [120/125], Loss: 2.2689\n",
            "Epoch [23/100], Step [10/125], Loss: 2.2503\n",
            "Epoch [23/100], Step [20/125], Loss: 2.2621\n",
            "Epoch [23/100], Step [30/125], Loss: 2.2265\n",
            "Epoch [23/100], Step [40/125], Loss: 2.1682\n",
            "Epoch [23/100], Step [50/125], Loss: 2.2256\n",
            "Epoch [23/100], Step [60/125], Loss: 2.4205\n",
            "Epoch [23/100], Step [70/125], Loss: 2.2411\n",
            "Epoch [23/100], Step [80/125], Loss: 2.4693\n",
            "Epoch [23/100], Step [90/125], Loss: 2.2626\n",
            "Epoch [23/100], Step [100/125], Loss: 2.3243\n",
            "Epoch [23/100], Step [110/125], Loss: 2.2489\n",
            "Epoch [23/100], Step [120/125], Loss: 2.2128\n",
            "Epoch [24/100], Step [10/125], Loss: 2.2419\n",
            "Epoch [24/100], Step [20/125], Loss: 2.1791\n",
            "Epoch [24/100], Step [30/125], Loss: 2.1414\n",
            "Epoch [24/100], Step [40/125], Loss: 2.0857\n",
            "Epoch [24/100], Step [50/125], Loss: 2.1393\n",
            "Epoch [24/100], Step [60/125], Loss: 2.3605\n",
            "Epoch [24/100], Step [70/125], Loss: 2.3072\n",
            "Epoch [24/100], Step [80/125], Loss: 2.4239\n",
            "Epoch [24/100], Step [90/125], Loss: 2.1669\n",
            "Epoch [24/100], Step [100/125], Loss: 2.2794\n",
            "Epoch [24/100], Step [110/125], Loss: 2.1635\n",
            "Epoch [24/100], Step [120/125], Loss: 2.1973\n",
            "Epoch [25/100], Step [10/125], Loss: 2.1908\n",
            "Epoch [25/100], Step [20/125], Loss: 2.0997\n",
            "Epoch [25/100], Step [30/125], Loss: 2.1016\n",
            "Epoch [25/100], Step [40/125], Loss: 2.0637\n",
            "Epoch [25/100], Step [50/125], Loss: 2.0967\n",
            "Epoch [25/100], Step [60/125], Loss: 2.3153\n",
            "Epoch [25/100], Step [70/125], Loss: 2.1619\n",
            "Epoch [25/100], Step [80/125], Loss: 2.4145\n",
            "Epoch [25/100], Step [90/125], Loss: 2.1974\n",
            "Epoch [25/100], Step [100/125], Loss: 2.1715\n",
            "Epoch [25/100], Step [110/125], Loss: 2.0693\n",
            "Epoch [25/100], Step [120/125], Loss: 2.1219\n",
            "Epoch [26/100], Step [10/125], Loss: 2.0910\n",
            "Epoch [26/100], Step [20/125], Loss: 1.9857\n",
            "Epoch [26/100], Step [30/125], Loss: 2.0002\n",
            "Epoch [26/100], Step [40/125], Loss: 1.9043\n",
            "Epoch [26/100], Step [50/125], Loss: 1.9725\n",
            "Epoch [26/100], Step [60/125], Loss: 2.1565\n",
            "Epoch [26/100], Step [70/125], Loss: 2.2002\n",
            "Epoch [26/100], Step [80/125], Loss: 2.3611\n",
            "Epoch [26/100], Step [90/125], Loss: 2.1144\n",
            "Epoch [26/100], Step [100/125], Loss: 2.1502\n",
            "Epoch [26/100], Step [110/125], Loss: 2.0985\n",
            "Epoch [26/100], Step [120/125], Loss: 2.0889\n",
            "Epoch [27/100], Step [10/125], Loss: 2.0142\n",
            "Epoch [27/100], Step [20/125], Loss: 1.9294\n",
            "Epoch [27/100], Step [30/125], Loss: 1.9661\n",
            "Epoch [27/100], Step [40/125], Loss: 1.8649\n",
            "Epoch [27/100], Step [50/125], Loss: 1.8688\n",
            "Epoch [27/100], Step [60/125], Loss: 2.0059\n",
            "Epoch [27/100], Step [70/125], Loss: 2.0194\n",
            "Epoch [27/100], Step [80/125], Loss: 2.1399\n",
            "Epoch [27/100], Step [90/125], Loss: 1.9625\n",
            "Epoch [27/100], Step [100/125], Loss: 1.9681\n",
            "Epoch [27/100], Step [110/125], Loss: 1.8567\n",
            "Epoch [27/100], Step [120/125], Loss: 1.8586\n",
            "Epoch [28/100], Step [10/125], Loss: 1.8448\n",
            "Epoch [28/100], Step [20/125], Loss: 1.8005\n",
            "Epoch [28/100], Step [30/125], Loss: 1.8532\n",
            "Epoch [28/100], Step [40/125], Loss: 1.7533\n",
            "Epoch [28/100], Step [50/125], Loss: 1.7527\n",
            "Epoch [28/100], Step [60/125], Loss: 1.8861\n",
            "Epoch [28/100], Step [70/125], Loss: 1.8609\n",
            "Epoch [28/100], Step [80/125], Loss: 2.0420\n",
            "Epoch [28/100], Step [90/125], Loss: 1.8776\n",
            "Epoch [28/100], Step [100/125], Loss: 1.8949\n",
            "Epoch [28/100], Step [110/125], Loss: 1.7611\n",
            "Epoch [28/100], Step [120/125], Loss: 1.7572\n",
            "Epoch [29/100], Step [10/125], Loss: 1.7111\n",
            "Epoch [29/100], Step [20/125], Loss: 1.6789\n",
            "Epoch [29/100], Step [30/125], Loss: 1.8080\n",
            "Epoch [29/100], Step [40/125], Loss: 1.6791\n",
            "Epoch [29/100], Step [50/125], Loss: 1.6667\n",
            "Epoch [29/100], Step [60/125], Loss: 1.7709\n",
            "Epoch [29/100], Step [70/125], Loss: 1.7088\n",
            "Epoch [29/100], Step [80/125], Loss: 1.8459\n",
            "Epoch [29/100], Step [90/125], Loss: 1.6953\n",
            "Epoch [29/100], Step [100/125], Loss: 1.7367\n",
            "Epoch [29/100], Step [110/125], Loss: 1.6133\n",
            "Epoch [29/100], Step [120/125], Loss: 1.6347\n",
            "Epoch [30/100], Step [10/125], Loss: 1.5880\n",
            "Epoch [30/100], Step [20/125], Loss: 1.5897\n",
            "Epoch [30/100], Step [30/125], Loss: 1.6777\n",
            "Epoch [30/100], Step [40/125], Loss: 1.5635\n",
            "Epoch [30/100], Step [50/125], Loss: 1.5260\n",
            "Epoch [30/100], Step [60/125], Loss: 1.6205\n",
            "Epoch [30/100], Step [70/125], Loss: 1.5490\n",
            "Epoch [30/100], Step [80/125], Loss: 1.7043\n",
            "Epoch [30/100], Step [90/125], Loss: 1.5383\n",
            "Epoch [30/100], Step [100/125], Loss: 1.5612\n",
            "Epoch [30/100], Step [110/125], Loss: 1.4821\n",
            "Epoch [30/100], Step [120/125], Loss: 1.5086\n",
            "Epoch [31/100], Step [10/125], Loss: 1.4724\n",
            "Epoch [31/100], Step [20/125], Loss: 1.4433\n",
            "Epoch [31/100], Step [30/125], Loss: 1.5399\n",
            "Epoch [31/100], Step [40/125], Loss: 1.4936\n",
            "Epoch [31/100], Step [50/125], Loss: 1.4368\n",
            "Epoch [31/100], Step [60/125], Loss: 1.5087\n",
            "Epoch [31/100], Step [70/125], Loss: 1.4375\n",
            "Epoch [31/100], Step [80/125], Loss: 1.5610\n",
            "Epoch [31/100], Step [90/125], Loss: 1.4074\n",
            "Epoch [31/100], Step [100/125], Loss: 1.4490\n",
            "Epoch [31/100], Step [110/125], Loss: 1.3860\n",
            "Epoch [31/100], Step [120/125], Loss: 1.3923\n",
            "Epoch [32/100], Step [10/125], Loss: 1.3621\n",
            "Epoch [32/100], Step [20/125], Loss: 1.3366\n",
            "Epoch [32/100], Step [30/125], Loss: 1.4122\n",
            "Epoch [32/100], Step [40/125], Loss: 1.3539\n",
            "Epoch [32/100], Step [50/125], Loss: 1.3282\n",
            "Epoch [32/100], Step [60/125], Loss: 1.3933\n",
            "Epoch [32/100], Step [70/125], Loss: 1.3392\n",
            "Epoch [32/100], Step [80/125], Loss: 1.4091\n",
            "Epoch [32/100], Step [90/125], Loss: 1.3335\n",
            "Epoch [32/100], Step [100/125], Loss: 1.3480\n",
            "Epoch [32/100], Step [110/125], Loss: 1.2987\n",
            "Epoch [32/100], Step [120/125], Loss: 1.2929\n",
            "Epoch [33/100], Step [10/125], Loss: 1.2850\n",
            "Epoch [33/100], Step [20/125], Loss: 1.2696\n",
            "Epoch [33/100], Step [30/125], Loss: 1.3044\n",
            "Epoch [33/100], Step [40/125], Loss: 1.2277\n",
            "Epoch [33/100], Step [50/125], Loss: 1.2120\n",
            "Epoch [33/100], Step [60/125], Loss: 1.3458\n",
            "Epoch [33/100], Step [70/125], Loss: 1.2921\n",
            "Epoch [33/100], Step [80/125], Loss: 1.3422\n",
            "Epoch [33/100], Step [90/125], Loss: 1.2243\n",
            "Epoch [33/100], Step [100/125], Loss: 1.2377\n",
            "Epoch [33/100], Step [110/125], Loss: 1.2429\n",
            "Epoch [33/100], Step [120/125], Loss: 1.2585\n",
            "Epoch [34/100], Step [10/125], Loss: 1.2589\n",
            "Epoch [34/100], Step [20/125], Loss: 1.2079\n",
            "Epoch [34/100], Step [30/125], Loss: 1.2888\n",
            "Epoch [34/100], Step [40/125], Loss: 1.1972\n",
            "Epoch [34/100], Step [50/125], Loss: 1.2266\n",
            "Epoch [34/100], Step [60/125], Loss: 1.2504\n",
            "Epoch [34/100], Step [70/125], Loss: 1.1625\n",
            "Epoch [34/100], Step [80/125], Loss: 1.2528\n",
            "Epoch [34/100], Step [90/125], Loss: 1.1749\n",
            "Epoch [34/100], Step [100/125], Loss: 1.1623\n",
            "Epoch [34/100], Step [110/125], Loss: 1.1540\n",
            "Epoch [34/100], Step [120/125], Loss: 1.1262\n",
            "Epoch [35/100], Step [10/125], Loss: 1.1339\n",
            "Epoch [35/100], Step [20/125], Loss: 1.1479\n",
            "Epoch [35/100], Step [30/125], Loss: 1.1913\n",
            "Epoch [35/100], Step [40/125], Loss: 1.1232\n",
            "Epoch [35/100], Step [50/125], Loss: 1.1327\n",
            "Epoch [35/100], Step [60/125], Loss: 1.1502\n",
            "Epoch [35/100], Step [70/125], Loss: 1.1075\n",
            "Epoch [35/100], Step [80/125], Loss: 1.1831\n",
            "Epoch [35/100], Step [90/125], Loss: 1.1003\n",
            "Epoch [35/100], Step [100/125], Loss: 1.0854\n",
            "Epoch [35/100], Step [110/125], Loss: 1.1121\n",
            "Epoch [35/100], Step [120/125], Loss: 1.0933\n",
            "Epoch [36/100], Step [10/125], Loss: 1.0485\n",
            "Epoch [36/100], Step [20/125], Loss: 1.0896\n",
            "Epoch [36/100], Step [30/125], Loss: 1.1108\n",
            "Epoch [36/100], Step [40/125], Loss: 0.9974\n",
            "Epoch [36/100], Step [50/125], Loss: 1.0269\n",
            "Epoch [36/100], Step [60/125], Loss: 1.0629\n",
            "Epoch [36/100], Step [70/125], Loss: 1.0445\n",
            "Epoch [36/100], Step [80/125], Loss: 1.0792\n",
            "Epoch [36/100], Step [90/125], Loss: 1.0032\n",
            "Epoch [36/100], Step [100/125], Loss: 0.9983\n",
            "Epoch [36/100], Step [110/125], Loss: 1.0074\n",
            "Epoch [36/100], Step [120/125], Loss: 0.9892\n",
            "Epoch [37/100], Step [10/125], Loss: 0.9408\n",
            "Epoch [37/100], Step [20/125], Loss: 0.9471\n",
            "Epoch [37/100], Step [30/125], Loss: 1.0087\n",
            "Epoch [37/100], Step [40/125], Loss: 0.9493\n",
            "Epoch [37/100], Step [50/125], Loss: 0.9541\n",
            "Epoch [37/100], Step [60/125], Loss: 0.9955\n",
            "Epoch [37/100], Step [70/125], Loss: 0.9567\n",
            "Epoch [37/100], Step [80/125], Loss: 0.9899\n",
            "Epoch [37/100], Step [90/125], Loss: 0.9330\n",
            "Epoch [37/100], Step [100/125], Loss: 0.9010\n",
            "Epoch [37/100], Step [110/125], Loss: 0.9078\n",
            "Epoch [37/100], Step [120/125], Loss: 0.9037\n",
            "Epoch [38/100], Step [10/125], Loss: 0.8854\n",
            "Epoch [38/100], Step [20/125], Loss: 0.8383\n",
            "Epoch [38/100], Step [30/125], Loss: 0.8925\n",
            "Epoch [38/100], Step [40/125], Loss: 0.8323\n",
            "Epoch [38/100], Step [50/125], Loss: 0.8866\n",
            "Epoch [38/100], Step [60/125], Loss: 0.9190\n",
            "Epoch [38/100], Step [70/125], Loss: 0.8913\n",
            "Epoch [38/100], Step [80/125], Loss: 0.9182\n",
            "Epoch [38/100], Step [90/125], Loss: 0.8299\n",
            "Epoch [38/100], Step [100/125], Loss: 0.8516\n",
            "Epoch [38/100], Step [110/125], Loss: 0.8289\n",
            "Epoch [38/100], Step [120/125], Loss: 0.8060\n",
            "Epoch [39/100], Step [10/125], Loss: 0.7975\n",
            "Epoch [39/100], Step [20/125], Loss: 0.7836\n",
            "Epoch [39/100], Step [30/125], Loss: 0.7990\n",
            "Epoch [39/100], Step [40/125], Loss: 0.7517\n",
            "Epoch [39/100], Step [50/125], Loss: 0.7820\n",
            "Epoch [39/100], Step [60/125], Loss: 0.8171\n",
            "Epoch [39/100], Step [70/125], Loss: 0.8119\n",
            "Epoch [39/100], Step [80/125], Loss: 0.8369\n",
            "Epoch [39/100], Step [90/125], Loss: 0.7695\n",
            "Epoch [39/100], Step [100/125], Loss: 0.7687\n",
            "Epoch [39/100], Step [110/125], Loss: 0.7607\n",
            "Epoch [39/100], Step [120/125], Loss: 0.7466\n",
            "Epoch [40/100], Step [10/125], Loss: 0.7383\n",
            "Epoch [40/100], Step [20/125], Loss: 0.7117\n",
            "Epoch [40/100], Step [30/125], Loss: 0.7462\n",
            "Epoch [40/100], Step [40/125], Loss: 0.6914\n",
            "Epoch [40/100], Step [50/125], Loss: 0.7269\n",
            "Epoch [40/100], Step [60/125], Loss: 0.7259\n",
            "Epoch [40/100], Step [70/125], Loss: 0.7238\n",
            "Epoch [40/100], Step [80/125], Loss: 0.7240\n",
            "Epoch [40/100], Step [90/125], Loss: 0.6974\n",
            "Epoch [40/100], Step [100/125], Loss: 0.6898\n",
            "Epoch [40/100], Step [110/125], Loss: 0.7196\n",
            "Epoch [40/100], Step [120/125], Loss: 0.6791\n",
            "Epoch [41/100], Step [10/125], Loss: 0.6973\n",
            "Epoch [41/100], Step [20/125], Loss: 0.6458\n",
            "Epoch [41/100], Step [30/125], Loss: 0.6729\n",
            "Epoch [41/100], Step [40/125], Loss: 0.6913\n",
            "Epoch [41/100], Step [50/125], Loss: 0.6873\n",
            "Epoch [41/100], Step [60/125], Loss: 0.7016\n",
            "Epoch [41/100], Step [70/125], Loss: 0.6793\n",
            "Epoch [41/100], Step [80/125], Loss: 0.6397\n",
            "Epoch [41/100], Step [90/125], Loss: 0.6123\n",
            "Epoch [41/100], Step [100/125], Loss: 0.6441\n",
            "Epoch [41/100], Step [110/125], Loss: 0.6801\n",
            "Epoch [41/100], Step [120/125], Loss: 0.6220\n",
            "Epoch [42/100], Step [10/125], Loss: 0.6517\n",
            "Epoch [42/100], Step [20/125], Loss: 0.6246\n",
            "Epoch [42/100], Step [30/125], Loss: 0.6461\n",
            "Epoch [42/100], Step [40/125], Loss: 0.5987\n",
            "Epoch [42/100], Step [50/125], Loss: 0.6467\n",
            "Epoch [42/100], Step [60/125], Loss: 0.6501\n",
            "Epoch [42/100], Step [70/125], Loss: 0.6549\n",
            "Epoch [42/100], Step [80/125], Loss: 0.6212\n",
            "Epoch [42/100], Step [90/125], Loss: 0.5646\n",
            "Epoch [42/100], Step [100/125], Loss: 0.5983\n",
            "Epoch [42/100], Step [110/125], Loss: 0.6054\n",
            "Epoch [42/100], Step [120/125], Loss: 0.6026\n",
            "Epoch [43/100], Step [10/125], Loss: 0.6160\n",
            "Epoch [43/100], Step [20/125], Loss: 0.6158\n",
            "Epoch [43/100], Step [30/125], Loss: 0.6220\n",
            "Epoch [43/100], Step [40/125], Loss: 0.5752\n",
            "Epoch [43/100], Step [50/125], Loss: 0.6161\n",
            "Epoch [43/100], Step [60/125], Loss: 0.6060\n",
            "Epoch [43/100], Step [70/125], Loss: 0.6153\n",
            "Epoch [43/100], Step [80/125], Loss: 0.5779\n",
            "Epoch [43/100], Step [90/125], Loss: 0.5579\n",
            "Epoch [43/100], Step [100/125], Loss: 0.5379\n",
            "Epoch [43/100], Step [110/125], Loss: 0.5673\n",
            "Epoch [43/100], Step [120/125], Loss: 0.5629\n",
            "Epoch [44/100], Step [10/125], Loss: 0.6117\n",
            "Epoch [44/100], Step [20/125], Loss: 0.5877\n",
            "Epoch [44/100], Step [30/125], Loss: 0.5800\n",
            "Epoch [44/100], Step [40/125], Loss: 0.5317\n",
            "Epoch [44/100], Step [50/125], Loss: 0.5884\n",
            "Epoch [44/100], Step [60/125], Loss: 0.5700\n",
            "Epoch [44/100], Step [70/125], Loss: 0.5542\n",
            "Epoch [44/100], Step [80/125], Loss: 0.5319\n",
            "Epoch [44/100], Step [90/125], Loss: 0.5293\n",
            "Epoch [44/100], Step [100/125], Loss: 0.5057\n",
            "Epoch [44/100], Step [110/125], Loss: 0.5150\n",
            "Epoch [44/100], Step [120/125], Loss: 0.5066\n",
            "Epoch [45/100], Step [10/125], Loss: 0.5317\n",
            "Epoch [45/100], Step [20/125], Loss: 0.4930\n",
            "Epoch [45/100], Step [30/125], Loss: 0.5368\n",
            "Epoch [45/100], Step [40/125], Loss: 0.5050\n",
            "Epoch [45/100], Step [50/125], Loss: 0.5344\n",
            "Epoch [45/100], Step [60/125], Loss: 0.5288\n",
            "Epoch [45/100], Step [70/125], Loss: 0.5067\n",
            "Epoch [45/100], Step [80/125], Loss: 0.4993\n",
            "Epoch [45/100], Step [90/125], Loss: 0.4801\n",
            "Epoch [45/100], Step [100/125], Loss: 0.4972\n",
            "Epoch [45/100], Step [110/125], Loss: 0.4549\n",
            "Epoch [45/100], Step [120/125], Loss: 0.4549\n",
            "Epoch [46/100], Step [10/125], Loss: 0.4673\n",
            "Epoch [46/100], Step [20/125], Loss: 0.4126\n",
            "Epoch [46/100], Step [30/125], Loss: 0.4652\n",
            "Epoch [46/100], Step [40/125], Loss: 0.4377\n",
            "Epoch [46/100], Step [50/125], Loss: 0.4527\n",
            "Epoch [46/100], Step [60/125], Loss: 0.4521\n",
            "Epoch [46/100], Step [70/125], Loss: 0.4405\n",
            "Epoch [46/100], Step [80/125], Loss: 0.4254\n",
            "Epoch [46/100], Step [90/125], Loss: 0.3965\n",
            "Epoch [46/100], Step [100/125], Loss: 0.4351\n",
            "Epoch [46/100], Step [110/125], Loss: 0.4297\n",
            "Epoch [46/100], Step [120/125], Loss: 0.3989\n",
            "Epoch [47/100], Step [10/125], Loss: 0.4100\n",
            "Epoch [47/100], Step [20/125], Loss: 0.3834\n",
            "Epoch [47/100], Step [30/125], Loss: 0.4184\n",
            "Epoch [47/100], Step [40/125], Loss: 0.3734\n",
            "Epoch [47/100], Step [50/125], Loss: 0.3931\n",
            "Epoch [47/100], Step [60/125], Loss: 0.3960\n",
            "Epoch [47/100], Step [70/125], Loss: 0.3999\n",
            "Epoch [47/100], Step [80/125], Loss: 0.3686\n",
            "Epoch [47/100], Step [90/125], Loss: 0.3346\n",
            "Epoch [47/100], Step [100/125], Loss: 0.3464\n",
            "Epoch [47/100], Step [110/125], Loss: 0.3546\n",
            "Epoch [47/100], Step [120/125], Loss: 0.3487\n",
            "Epoch [48/100], Step [10/125], Loss: 0.3584\n",
            "Epoch [48/100], Step [20/125], Loss: 0.3518\n",
            "Epoch [48/100], Step [30/125], Loss: 0.3682\n",
            "Epoch [48/100], Step [40/125], Loss: 0.3417\n",
            "Epoch [48/100], Step [50/125], Loss: 0.3627\n",
            "Epoch [48/100], Step [60/125], Loss: 0.3636\n",
            "Epoch [48/100], Step [70/125], Loss: 0.3650\n",
            "Epoch [48/100], Step [80/125], Loss: 0.3410\n",
            "Epoch [48/100], Step [90/125], Loss: 0.3186\n",
            "Epoch [48/100], Step [100/125], Loss: 0.3045\n",
            "Epoch [48/100], Step [110/125], Loss: 0.3035\n",
            "Epoch [48/100], Step [120/125], Loss: 0.3098\n",
            "Epoch [49/100], Step [10/125], Loss: 0.3429\n",
            "Epoch [49/100], Step [20/125], Loss: 0.3239\n",
            "Epoch [49/100], Step [30/125], Loss: 0.3330\n",
            "Epoch [49/100], Step [40/125], Loss: 0.3070\n",
            "Epoch [49/100], Step [50/125], Loss: 0.3070\n",
            "Epoch [49/100], Step [60/125], Loss: 0.3433\n",
            "Epoch [49/100], Step [70/125], Loss: 0.3290\n",
            "Epoch [49/100], Step [80/125], Loss: 0.2946\n",
            "Epoch [49/100], Step [90/125], Loss: 0.2724\n",
            "Epoch [49/100], Step [100/125], Loss: 0.2687\n",
            "Epoch [49/100], Step [110/125], Loss: 0.2654\n",
            "Epoch [49/100], Step [120/125], Loss: 0.2723\n",
            "Epoch [50/100], Step [10/125], Loss: 0.3180\n",
            "Epoch [50/100], Step [20/125], Loss: 0.2920\n",
            "Epoch [50/100], Step [30/125], Loss: 0.2740\n",
            "Epoch [50/100], Step [40/125], Loss: 0.2750\n",
            "Epoch [50/100], Step [50/125], Loss: 0.2795\n",
            "Epoch [50/100], Step [60/125], Loss: 0.3096\n",
            "Epoch [50/100], Step [70/125], Loss: 0.3074\n",
            "Epoch [50/100], Step [80/125], Loss: 0.2628\n",
            "Epoch [50/100], Step [90/125], Loss: 0.2525\n",
            "Epoch [50/100], Step [100/125], Loss: 0.2470\n",
            "Epoch [50/100], Step [110/125], Loss: 0.2356\n",
            "Epoch [50/100], Step [120/125], Loss: 0.2078\n",
            "Epoch [51/100], Step [10/125], Loss: 0.2568\n",
            "Epoch [51/100], Step [20/125], Loss: 0.2370\n",
            "Epoch [51/100], Step [30/125], Loss: 0.2661\n",
            "Epoch [51/100], Step [40/125], Loss: 0.2514\n",
            "Epoch [51/100], Step [50/125], Loss: 0.2573\n",
            "Epoch [51/100], Step [60/125], Loss: 0.2470\n",
            "Epoch [51/100], Step [70/125], Loss: 0.2761\n",
            "Epoch [51/100], Step [80/125], Loss: 0.2822\n",
            "Epoch [51/100], Step [90/125], Loss: 0.2322\n",
            "Epoch [51/100], Step [100/125], Loss: 0.2294\n",
            "Epoch [51/100], Step [110/125], Loss: 0.2079\n",
            "Epoch [51/100], Step [120/125], Loss: 0.1906\n",
            "Epoch [52/100], Step [10/125], Loss: 0.2181\n",
            "Epoch [52/100], Step [20/125], Loss: 0.2029\n",
            "Epoch [52/100], Step [30/125], Loss: 0.2350\n",
            "Epoch [52/100], Step [40/125], Loss: 0.2255\n",
            "Epoch [52/100], Step [50/125], Loss: 0.2370\n",
            "Epoch [52/100], Step [60/125], Loss: 0.2379\n",
            "Epoch [52/100], Step [70/125], Loss: 0.2614\n",
            "Epoch [52/100], Step [80/125], Loss: 0.2605\n",
            "Epoch [52/100], Step [90/125], Loss: 0.2366\n",
            "Epoch [52/100], Step [100/125], Loss: 0.2265\n",
            "Epoch [52/100], Step [110/125], Loss: 0.2041\n",
            "Epoch [52/100], Step [120/125], Loss: 0.1715\n",
            "Epoch [53/100], Step [10/125], Loss: 0.2005\n",
            "Epoch [53/100], Step [20/125], Loss: 0.1708\n",
            "Epoch [53/100], Step [30/125], Loss: 0.1938\n",
            "Epoch [53/100], Step [40/125], Loss: 0.1954\n",
            "Epoch [53/100], Step [50/125], Loss: 0.2106\n",
            "Epoch [53/100], Step [60/125], Loss: 0.1993\n",
            "Epoch [53/100], Step [70/125], Loss: 0.2202\n",
            "Epoch [53/100], Step [80/125], Loss: 0.2135\n",
            "Epoch [53/100], Step [90/125], Loss: 0.1890\n",
            "Epoch [53/100], Step [100/125], Loss: 0.1996\n",
            "Epoch [53/100], Step [110/125], Loss: 0.2015\n",
            "Epoch [53/100], Step [120/125], Loss: 0.1719\n",
            "Epoch [54/100], Step [10/125], Loss: 0.2025\n",
            "Epoch [54/100], Step [20/125], Loss: 0.1736\n",
            "Epoch [54/100], Step [30/125], Loss: 0.1918\n",
            "Epoch [54/100], Step [40/125], Loss: 0.1652\n",
            "Epoch [54/100], Step [50/125], Loss: 0.1893\n",
            "Epoch [54/100], Step [60/125], Loss: 0.1817\n",
            "Epoch [54/100], Step [70/125], Loss: 0.1960\n",
            "Epoch [54/100], Step [80/125], Loss: 0.1744\n",
            "Epoch [54/100], Step [90/125], Loss: 0.1593\n",
            "Epoch [54/100], Step [100/125], Loss: 0.1519\n",
            "Epoch [54/100], Step [110/125], Loss: 0.1515\n",
            "Epoch [54/100], Step [120/125], Loss: 0.1499\n",
            "Epoch [55/100], Step [10/125], Loss: 0.2291\n",
            "Epoch [55/100], Step [20/125], Loss: 0.1907\n",
            "Epoch [55/100], Step [30/125], Loss: 0.1676\n",
            "Epoch [55/100], Step [40/125], Loss: 0.1575\n",
            "Epoch [55/100], Step [50/125], Loss: 0.1629\n",
            "Epoch [55/100], Step [60/125], Loss: 0.1572\n",
            "Epoch [55/100], Step [70/125], Loss: 0.1652\n",
            "Epoch [55/100], Step [80/125], Loss: 0.1568\n",
            "Epoch [55/100], Step [90/125], Loss: 0.1298\n",
            "Epoch [55/100], Step [100/125], Loss: 0.1337\n",
            "Epoch [55/100], Step [110/125], Loss: 0.1188\n",
            "Epoch [55/100], Step [120/125], Loss: 0.1204\n",
            "Epoch [56/100], Step [10/125], Loss: 0.1876\n",
            "Epoch [56/100], Step [20/125], Loss: 0.1845\n",
            "Epoch [56/100], Step [30/125], Loss: 0.1677\n",
            "Epoch [56/100], Step [40/125], Loss: 0.1404\n",
            "Epoch [56/100], Step [50/125], Loss: 0.1571\n",
            "Epoch [56/100], Step [60/125], Loss: 0.1675\n",
            "Epoch [56/100], Step [70/125], Loss: 0.1686\n",
            "Epoch [56/100], Step [80/125], Loss: 0.1709\n",
            "Epoch [56/100], Step [90/125], Loss: 0.1388\n",
            "Epoch [56/100], Step [100/125], Loss: 0.1262\n",
            "Epoch [56/100], Step [110/125], Loss: 0.1167\n",
            "Epoch [56/100], Step [120/125], Loss: 0.1071\n",
            "Epoch [57/100], Step [10/125], Loss: 0.1639\n",
            "Epoch [57/100], Step [20/125], Loss: 0.1472\n",
            "Epoch [57/100], Step [30/125], Loss: 0.1596\n",
            "Epoch [57/100], Step [40/125], Loss: 0.1452\n",
            "Epoch [57/100], Step [50/125], Loss: 0.1832\n",
            "Epoch [57/100], Step [60/125], Loss: 0.1984\n",
            "Epoch [57/100], Step [70/125], Loss: 0.1854\n",
            "Epoch [57/100], Step [80/125], Loss: 0.2158\n",
            "Epoch [57/100], Step [90/125], Loss: 0.1807\n",
            "Epoch [57/100], Step [100/125], Loss: 0.1524\n",
            "Epoch [57/100], Step [110/125], Loss: 0.1968\n",
            "Epoch [57/100], Step [120/125], Loss: 0.2070\n",
            "Epoch [58/100], Step [10/125], Loss: 0.2274\n",
            "Epoch [58/100], Step [20/125], Loss: 0.1769\n",
            "Epoch [58/100], Step [30/125], Loss: 0.1790\n",
            "Epoch [58/100], Step [40/125], Loss: 0.1616\n",
            "Epoch [58/100], Step [50/125], Loss: 0.2452\n",
            "Epoch [58/100], Step [60/125], Loss: 0.2223\n",
            "Epoch [58/100], Step [70/125], Loss: 0.2128\n",
            "Epoch [58/100], Step [80/125], Loss: 0.3600\n",
            "Epoch [58/100], Step [90/125], Loss: 0.3150\n",
            "Epoch [58/100], Step [100/125], Loss: 0.3078\n",
            "Epoch [58/100], Step [110/125], Loss: 0.2686\n",
            "Epoch [58/100], Step [120/125], Loss: 0.2440\n",
            "Epoch [59/100], Step [10/125], Loss: 0.2314\n",
            "Epoch [59/100], Step [20/125], Loss: 0.2260\n",
            "Epoch [59/100], Step [30/125], Loss: 0.1894\n",
            "Epoch [59/100], Step [40/125], Loss: 0.1792\n",
            "Epoch [59/100], Step [50/125], Loss: 0.2224\n",
            "Epoch [59/100], Step [60/125], Loss: 0.2554\n",
            "Epoch [59/100], Step [70/125], Loss: 0.2046\n",
            "Epoch [59/100], Step [80/125], Loss: 0.2157\n",
            "Epoch [59/100], Step [90/125], Loss: 0.1925\n",
            "Epoch [59/100], Step [100/125], Loss: 0.1621\n",
            "Epoch [59/100], Step [110/125], Loss: 0.1662\n",
            "Epoch [59/100], Step [120/125], Loss: 0.1941\n",
            "Epoch [60/100], Step [10/125], Loss: 0.1637\n",
            "Epoch [60/100], Step [20/125], Loss: 0.1532\n",
            "Epoch [60/100], Step [30/125], Loss: 0.1722\n",
            "Epoch [60/100], Step [40/125], Loss: 0.1344\n",
            "Epoch [60/100], Step [50/125], Loss: 0.1360\n",
            "Epoch [60/100], Step [60/125], Loss: 0.1497\n",
            "Epoch [60/100], Step [70/125], Loss: 0.1475\n",
            "Epoch [60/100], Step [80/125], Loss: 0.1280\n",
            "Epoch [60/100], Step [90/125], Loss: 0.1121\n",
            "Epoch [60/100], Step [100/125], Loss: 0.1060\n",
            "Epoch [60/100], Step [110/125], Loss: 0.0985\n",
            "Epoch [60/100], Step [120/125], Loss: 0.1030\n",
            "Epoch [61/100], Step [10/125], Loss: 0.1180\n",
            "Epoch [61/100], Step [20/125], Loss: 0.1119\n",
            "Epoch [61/100], Step [30/125], Loss: 0.1178\n",
            "Epoch [61/100], Step [40/125], Loss: 0.1085\n",
            "Epoch [61/100], Step [50/125], Loss: 0.0891\n",
            "Epoch [61/100], Step [60/125], Loss: 0.1044\n",
            "Epoch [61/100], Step [70/125], Loss: 0.1041\n",
            "Epoch [61/100], Step [80/125], Loss: 0.0996\n",
            "Epoch [61/100], Step [90/125], Loss: 0.0778\n",
            "Epoch [61/100], Step [100/125], Loss: 0.0766\n",
            "Epoch [61/100], Step [110/125], Loss: 0.0642\n",
            "Epoch [61/100], Step [120/125], Loss: 0.0726\n",
            "Epoch [62/100], Step [10/125], Loss: 0.0876\n",
            "Epoch [62/100], Step [20/125], Loss: 0.0730\n",
            "Epoch [62/100], Step [30/125], Loss: 0.0923\n",
            "Epoch [62/100], Step [40/125], Loss: 0.0754\n",
            "Epoch [62/100], Step [50/125], Loss: 0.0930\n",
            "Epoch [62/100], Step [60/125], Loss: 0.0981\n",
            "Epoch [62/100], Step [70/125], Loss: 0.0926\n",
            "Epoch [62/100], Step [80/125], Loss: 0.0915\n",
            "Epoch [62/100], Step [90/125], Loss: 0.0764\n",
            "Epoch [62/100], Step [100/125], Loss: 0.0632\n",
            "Epoch [62/100], Step [110/125], Loss: 0.0533\n",
            "Epoch [62/100], Step [120/125], Loss: 0.0579\n",
            "Epoch [63/100], Step [10/125], Loss: 0.0719\n",
            "Epoch [63/100], Step [20/125], Loss: 0.0610\n",
            "Epoch [63/100], Step [30/125], Loss: 0.0737\n",
            "Epoch [63/100], Step [40/125], Loss: 0.0595\n",
            "Epoch [63/100], Step [50/125], Loss: 0.0811\n",
            "Epoch [63/100], Step [60/125], Loss: 0.0772\n",
            "Epoch [63/100], Step [70/125], Loss: 0.0802\n",
            "Epoch [63/100], Step [80/125], Loss: 0.0931\n",
            "Epoch [63/100], Step [90/125], Loss: 0.0799\n",
            "Epoch [63/100], Step [100/125], Loss: 0.0561\n",
            "Epoch [63/100], Step [110/125], Loss: 0.0526\n",
            "Epoch [63/100], Step [120/125], Loss: 0.0469\n",
            "Epoch [64/100], Step [10/125], Loss: 0.0635\n",
            "Epoch [64/100], Step [20/125], Loss: 0.0496\n",
            "Epoch [64/100], Step [30/125], Loss: 0.0604\n",
            "Epoch [64/100], Step [40/125], Loss: 0.0526\n",
            "Epoch [64/100], Step [50/125], Loss: 0.0582\n",
            "Epoch [64/100], Step [60/125], Loss: 0.0758\n",
            "Epoch [64/100], Step [70/125], Loss: 0.0807\n",
            "Epoch [64/100], Step [80/125], Loss: 0.0798\n",
            "Epoch [64/100], Step [90/125], Loss: 0.0683\n",
            "Epoch [64/100], Step [100/125], Loss: 0.0576\n",
            "Epoch [64/100], Step [110/125], Loss: 0.0512\n",
            "Epoch [64/100], Step [120/125], Loss: 0.0449\n",
            "Epoch [65/100], Step [10/125], Loss: 0.0558\n",
            "Epoch [65/100], Step [20/125], Loss: 0.0434\n",
            "Epoch [65/100], Step [30/125], Loss: 0.0510\n",
            "Epoch [65/100], Step [40/125], Loss: 0.0425\n",
            "Epoch [65/100], Step [50/125], Loss: 0.0410\n",
            "Epoch [65/100], Step [60/125], Loss: 0.0598\n",
            "Epoch [65/100], Step [70/125], Loss: 0.0531\n",
            "Epoch [65/100], Step [80/125], Loss: 0.0653\n",
            "Epoch [65/100], Step [90/125], Loss: 0.0619\n",
            "Epoch [65/100], Step [100/125], Loss: 0.0471\n",
            "Epoch [65/100], Step [110/125], Loss: 0.0501\n",
            "Epoch [65/100], Step [120/125], Loss: 0.0338\n",
            "Epoch [66/100], Step [10/125], Loss: 0.0489\n",
            "Epoch [66/100], Step [20/125], Loss: 0.0403\n",
            "Epoch [66/100], Step [30/125], Loss: 0.0426\n",
            "Epoch [66/100], Step [40/125], Loss: 0.0374\n",
            "Epoch [66/100], Step [50/125], Loss: 0.0324\n",
            "Epoch [66/100], Step [60/125], Loss: 0.0548\n",
            "Epoch [66/100], Step [70/125], Loss: 0.0490\n",
            "Epoch [66/100], Step [80/125], Loss: 0.0519\n",
            "Epoch [66/100], Step [90/125], Loss: 0.0472\n",
            "Epoch [66/100], Step [100/125], Loss: 0.0423\n",
            "Epoch [66/100], Step [110/125], Loss: 0.0374\n",
            "Epoch [66/100], Step [120/125], Loss: 0.0371\n",
            "Epoch [67/100], Step [10/125], Loss: 0.0480\n",
            "Epoch [67/100], Step [20/125], Loss: 0.0357\n",
            "Epoch [67/100], Step [30/125], Loss: 0.0424\n",
            "Epoch [67/100], Step [40/125], Loss: 0.0373\n",
            "Epoch [67/100], Step [50/125], Loss: 0.0298\n",
            "Epoch [67/100], Step [60/125], Loss: 0.0409\n",
            "Epoch [67/100], Step [70/125], Loss: 0.0359\n",
            "Epoch [67/100], Step [80/125], Loss: 0.0405\n",
            "Epoch [67/100], Step [90/125], Loss: 0.0359\n",
            "Epoch [67/100], Step [100/125], Loss: 0.0320\n",
            "Epoch [67/100], Step [110/125], Loss: 0.0286\n",
            "Epoch [67/100], Step [120/125], Loss: 0.0305\n",
            "Epoch [68/100], Step [10/125], Loss: 0.0392\n",
            "Epoch [68/100], Step [20/125], Loss: 0.0375\n",
            "Epoch [68/100], Step [30/125], Loss: 0.0380\n",
            "Epoch [68/100], Step [40/125], Loss: 0.0362\n",
            "Epoch [68/100], Step [50/125], Loss: 0.0323\n",
            "Epoch [68/100], Step [60/125], Loss: 0.0378\n",
            "Epoch [68/100], Step [70/125], Loss: 0.0342\n",
            "Epoch [68/100], Step [80/125], Loss: 0.0364\n",
            "Epoch [68/100], Step [90/125], Loss: 0.0327\n",
            "Epoch [68/100], Step [100/125], Loss: 0.0294\n",
            "Epoch [68/100], Step [110/125], Loss: 0.0233\n",
            "Epoch [68/100], Step [120/125], Loss: 0.0252\n",
            "Epoch [69/100], Step [10/125], Loss: 0.0362\n",
            "Epoch [69/100], Step [20/125], Loss: 0.0329\n",
            "Epoch [69/100], Step [30/125], Loss: 0.0342\n",
            "Epoch [69/100], Step [40/125], Loss: 0.0345\n",
            "Epoch [69/100], Step [50/125], Loss: 0.0293\n",
            "Epoch [69/100], Step [60/125], Loss: 0.0324\n",
            "Epoch [69/100], Step [70/125], Loss: 0.0306\n",
            "Epoch [69/100], Step [80/125], Loss: 0.0327\n",
            "Epoch [69/100], Step [90/125], Loss: 0.0271\n",
            "Epoch [69/100], Step [100/125], Loss: 0.0218\n",
            "Epoch [69/100], Step [110/125], Loss: 0.0213\n",
            "Epoch [69/100], Step [120/125], Loss: 0.0187\n",
            "Epoch [70/100], Step [10/125], Loss: 0.0270\n",
            "Epoch [70/100], Step [20/125], Loss: 0.0241\n",
            "Epoch [70/100], Step [30/125], Loss: 0.0276\n",
            "Epoch [70/100], Step [40/125], Loss: 0.0250\n",
            "Epoch [70/100], Step [50/125], Loss: 0.0219\n",
            "Epoch [70/100], Step [60/125], Loss: 0.0279\n",
            "Epoch [70/100], Step [70/125], Loss: 0.0228\n",
            "Epoch [70/100], Step [80/125], Loss: 0.0270\n",
            "Epoch [70/100], Step [90/125], Loss: 0.0234\n",
            "Epoch [70/100], Step [100/125], Loss: 0.0195\n",
            "Epoch [70/100], Step [110/125], Loss: 0.0181\n",
            "Epoch [70/100], Step [120/125], Loss: 0.0162\n",
            "Epoch [71/100], Step [10/125], Loss: 0.0271\n",
            "Epoch [71/100], Step [20/125], Loss: 0.0214\n",
            "Epoch [71/100], Step [30/125], Loss: 0.0239\n",
            "Epoch [71/100], Step [40/125], Loss: 0.0220\n",
            "Epoch [71/100], Step [50/125], Loss: 0.0191\n",
            "Epoch [71/100], Step [60/125], Loss: 0.0248\n",
            "Epoch [71/100], Step [70/125], Loss: 0.0182\n",
            "Epoch [71/100], Step [80/125], Loss: 0.0278\n",
            "Epoch [71/100], Step [90/125], Loss: 0.0203\n",
            "Epoch [71/100], Step [100/125], Loss: 0.0177\n",
            "Epoch [71/100], Step [110/125], Loss: 0.0144\n",
            "Epoch [71/100], Step [120/125], Loss: 0.0144\n",
            "Epoch [72/100], Step [10/125], Loss: 0.0263\n",
            "Epoch [72/100], Step [20/125], Loss: 0.0227\n",
            "Epoch [72/100], Step [30/125], Loss: 0.0239\n",
            "Epoch [72/100], Step [40/125], Loss: 0.0247\n",
            "Epoch [72/100], Step [50/125], Loss: 0.0196\n",
            "Epoch [72/100], Step [60/125], Loss: 0.0231\n",
            "Epoch [72/100], Step [70/125], Loss: 0.0173\n",
            "Epoch [72/100], Step [80/125], Loss: 0.0252\n",
            "Epoch [72/100], Step [90/125], Loss: 0.0171\n",
            "Epoch [72/100], Step [100/125], Loss: 0.0164\n",
            "Epoch [72/100], Step [110/125], Loss: 0.0133\n",
            "Epoch [72/100], Step [120/125], Loss: 0.0126\n",
            "Epoch [73/100], Step [10/125], Loss: 0.0226\n",
            "Epoch [73/100], Step [20/125], Loss: 0.0183\n",
            "Epoch [73/100], Step [30/125], Loss: 0.0227\n",
            "Epoch [73/100], Step [40/125], Loss: 0.0219\n",
            "Epoch [73/100], Step [50/125], Loss: 0.0153\n",
            "Epoch [73/100], Step [60/125], Loss: 0.0188\n",
            "Epoch [73/100], Step [70/125], Loss: 0.0143\n",
            "Epoch [73/100], Step [80/125], Loss: 0.0210\n",
            "Epoch [73/100], Step [90/125], Loss: 0.0147\n",
            "Epoch [73/100], Step [100/125], Loss: 0.0142\n",
            "Epoch [73/100], Step [110/125], Loss: 0.0114\n",
            "Epoch [73/100], Step [120/125], Loss: 0.0105\n",
            "Epoch [74/100], Step [10/125], Loss: 0.0177\n",
            "Epoch [74/100], Step [20/125], Loss: 0.0149\n",
            "Epoch [74/100], Step [30/125], Loss: 0.0190\n",
            "Epoch [74/100], Step [40/125], Loss: 0.0164\n",
            "Epoch [74/100], Step [50/125], Loss: 0.0133\n",
            "Epoch [74/100], Step [60/125], Loss: 0.0174\n",
            "Epoch [74/100], Step [70/125], Loss: 0.0132\n",
            "Epoch [74/100], Step [80/125], Loss: 0.0179\n",
            "Epoch [74/100], Step [90/125], Loss: 0.0197\n",
            "Epoch [74/100], Step [100/125], Loss: 0.0155\n",
            "Epoch [74/100], Step [110/125], Loss: 0.0113\n",
            "Epoch [74/100], Step [120/125], Loss: 0.0112\n",
            "Epoch [75/100], Step [10/125], Loss: 0.0186\n",
            "Epoch [75/100], Step [20/125], Loss: 0.0139\n",
            "Epoch [75/100], Step [30/125], Loss: 0.0176\n",
            "Epoch [75/100], Step [40/125], Loss: 0.0142\n",
            "Epoch [75/100], Step [50/125], Loss: 0.0127\n",
            "Epoch [75/100], Step [60/125], Loss: 0.0214\n",
            "Epoch [75/100], Step [70/125], Loss: 0.0141\n",
            "Epoch [75/100], Step [80/125], Loss: 0.0178\n",
            "Epoch [75/100], Step [90/125], Loss: 0.0227\n",
            "Epoch [75/100], Step [100/125], Loss: 0.0134\n",
            "Epoch [75/100], Step [110/125], Loss: 0.0123\n",
            "Epoch [75/100], Step [120/125], Loss: 0.0110\n",
            "Epoch [76/100], Step [10/125], Loss: 0.0173\n",
            "Epoch [76/100], Step [20/125], Loss: 0.0138\n",
            "Epoch [76/100], Step [30/125], Loss: 0.0146\n",
            "Epoch [76/100], Step [40/125], Loss: 0.0129\n",
            "Epoch [76/100], Step [50/125], Loss: 0.0114\n",
            "Epoch [76/100], Step [60/125], Loss: 0.0165\n",
            "Epoch [76/100], Step [70/125], Loss: 0.0148\n",
            "Epoch [76/100], Step [80/125], Loss: 0.0176\n",
            "Epoch [76/100], Step [90/125], Loss: 0.0160\n",
            "Epoch [76/100], Step [100/125], Loss: 0.0110\n",
            "Epoch [76/100], Step [110/125], Loss: 0.0110\n",
            "Epoch [76/100], Step [120/125], Loss: 0.0095\n",
            "Epoch [77/100], Step [10/125], Loss: 0.0193\n",
            "Epoch [77/100], Step [20/125], Loss: 0.0131\n",
            "Epoch [77/100], Step [30/125], Loss: 0.0173\n",
            "Epoch [77/100], Step [40/125], Loss: 0.0144\n",
            "Epoch [77/100], Step [50/125], Loss: 0.0126\n",
            "Epoch [77/100], Step [60/125], Loss: 0.0153\n",
            "Epoch [77/100], Step [70/125], Loss: 0.0132\n",
            "Epoch [77/100], Step [80/125], Loss: 0.0138\n",
            "Epoch [77/100], Step [90/125], Loss: 0.0124\n",
            "Epoch [77/100], Step [100/125], Loss: 0.0095\n",
            "Epoch [77/100], Step [110/125], Loss: 0.0101\n",
            "Epoch [77/100], Step [120/125], Loss: 0.0095\n",
            "Epoch [78/100], Step [10/125], Loss: 0.0171\n",
            "Epoch [78/100], Step [20/125], Loss: 0.0140\n",
            "Epoch [78/100], Step [30/125], Loss: 0.0166\n",
            "Epoch [78/100], Step [40/125], Loss: 0.0146\n",
            "Epoch [78/100], Step [50/125], Loss: 0.0132\n",
            "Epoch [78/100], Step [60/125], Loss: 0.0137\n",
            "Epoch [78/100], Step [70/125], Loss: 0.0134\n",
            "Epoch [78/100], Step [80/125], Loss: 0.0148\n",
            "Epoch [78/100], Step [90/125], Loss: 0.0133\n",
            "Epoch [78/100], Step [100/125], Loss: 0.0091\n",
            "Epoch [78/100], Step [110/125], Loss: 0.0106\n",
            "Epoch [78/100], Step [120/125], Loss: 0.0104\n",
            "Epoch [79/100], Step [10/125], Loss: 0.0129\n",
            "Epoch [79/100], Step [20/125], Loss: 0.0138\n",
            "Epoch [79/100], Step [30/125], Loss: 0.0176\n",
            "Epoch [79/100], Step [40/125], Loss: 0.0145\n",
            "Epoch [79/100], Step [50/125], Loss: 0.0151\n",
            "Epoch [79/100], Step [60/125], Loss: 0.0136\n",
            "Epoch [79/100], Step [70/125], Loss: 0.0146\n",
            "Epoch [79/100], Step [80/125], Loss: 0.0180\n",
            "Epoch [79/100], Step [90/125], Loss: 0.0133\n",
            "Epoch [79/100], Step [100/125], Loss: 0.0106\n",
            "Epoch [79/100], Step [110/125], Loss: 0.0118\n",
            "Epoch [79/100], Step [120/125], Loss: 0.0101\n",
            "Epoch [80/100], Step [10/125], Loss: 0.0133\n",
            "Epoch [80/100], Step [20/125], Loss: 0.0122\n",
            "Epoch [80/100], Step [30/125], Loss: 0.0152\n",
            "Epoch [80/100], Step [40/125], Loss: 0.0166\n",
            "Epoch [80/100], Step [50/125], Loss: 0.0134\n",
            "Epoch [80/100], Step [60/125], Loss: 0.0145\n",
            "Epoch [80/100], Step [70/125], Loss: 0.0140\n",
            "Epoch [80/100], Step [80/125], Loss: 0.0194\n",
            "Epoch [80/100], Step [90/125], Loss: 0.0107\n",
            "Epoch [80/100], Step [100/125], Loss: 0.0121\n",
            "Epoch [80/100], Step [110/125], Loss: 0.0204\n",
            "Epoch [80/100], Step [120/125], Loss: 0.0146\n",
            "Epoch [81/100], Step [10/125], Loss: 0.0191\n",
            "Epoch [81/100], Step [20/125], Loss: 0.0146\n",
            "Epoch [81/100], Step [30/125], Loss: 0.0204\n",
            "Epoch [81/100], Step [40/125], Loss: 0.0167\n",
            "Epoch [81/100], Step [50/125], Loss: 0.0145\n",
            "Epoch [81/100], Step [60/125], Loss: 0.0167\n",
            "Epoch [81/100], Step [70/125], Loss: 0.0149\n",
            "Epoch [81/100], Step [80/125], Loss: 0.0196\n",
            "Epoch [81/100], Step [90/125], Loss: 0.0152\n",
            "Epoch [81/100], Step [100/125], Loss: 0.0238\n",
            "Epoch [81/100], Step [110/125], Loss: 0.0260\n",
            "Epoch [81/100], Step [120/125], Loss: 0.0269\n",
            "Epoch [82/100], Step [10/125], Loss: 0.0587\n",
            "Epoch [82/100], Step [20/125], Loss: 0.1517\n",
            "Epoch [82/100], Step [30/125], Loss: 0.5414\n",
            "Epoch [82/100], Step [40/125], Loss: 0.8366\n",
            "Epoch [82/100], Step [50/125], Loss: 1.0564\n",
            "Epoch [82/100], Step [60/125], Loss: 1.6088\n",
            "Epoch [82/100], Step [70/125], Loss: 1.2248\n",
            "Epoch [82/100], Step [80/125], Loss: 1.2413\n",
            "Epoch [82/100], Step [90/125], Loss: 0.8320\n",
            "Epoch [82/100], Step [100/125], Loss: 0.7402\n",
            "Epoch [82/100], Step [110/125], Loss: 0.6505\n",
            "Epoch [82/100], Step [120/125], Loss: 0.4974\n",
            "Epoch [83/100], Step [10/125], Loss: 0.4890\n",
            "Epoch [83/100], Step [20/125], Loss: 0.5006\n",
            "Epoch [83/100], Step [30/125], Loss: 0.5121\n",
            "Epoch [83/100], Step [40/125], Loss: 0.4267\n",
            "Epoch [83/100], Step [50/125], Loss: 0.4332\n",
            "Epoch [83/100], Step [60/125], Loss: 0.4568\n",
            "Epoch [83/100], Step [70/125], Loss: 0.2933\n",
            "Epoch [83/100], Step [80/125], Loss: 0.3119\n",
            "Epoch [83/100], Step [90/125], Loss: 0.2447\n",
            "Epoch [83/100], Step [100/125], Loss: 0.2277\n",
            "Epoch [83/100], Step [110/125], Loss: 0.1926\n",
            "Epoch [83/100], Step [120/125], Loss: 0.1298\n",
            "Epoch [84/100], Step [10/125], Loss: 0.1735\n",
            "Epoch [84/100], Step [20/125], Loss: 0.1438\n",
            "Epoch [84/100], Step [30/125], Loss: 0.1287\n",
            "Epoch [84/100], Step [40/125], Loss: 0.1266\n",
            "Epoch [84/100], Step [50/125], Loss: 0.1549\n",
            "Epoch [84/100], Step [60/125], Loss: 0.1255\n",
            "Epoch [84/100], Step [70/125], Loss: 0.0898\n",
            "Epoch [84/100], Step [80/125], Loss: 0.0896\n",
            "Epoch [84/100], Step [90/125], Loss: 0.0774\n",
            "Epoch [84/100], Step [100/125], Loss: 0.0767\n",
            "Epoch [84/100], Step [110/125], Loss: 0.0592\n",
            "Epoch [84/100], Step [120/125], Loss: 0.0560\n",
            "Epoch [85/100], Step [10/125], Loss: 0.0651\n",
            "Epoch [85/100], Step [20/125], Loss: 0.0644\n",
            "Epoch [85/100], Step [30/125], Loss: 0.0563\n",
            "Epoch [85/100], Step [40/125], Loss: 0.0512\n",
            "Epoch [85/100], Step [50/125], Loss: 0.0482\n",
            "Epoch [85/100], Step [60/125], Loss: 0.0565\n",
            "Epoch [85/100], Step [70/125], Loss: 0.0408\n",
            "Epoch [85/100], Step [80/125], Loss: 0.0393\n",
            "Epoch [85/100], Step [90/125], Loss: 0.0356\n",
            "Epoch [85/100], Step [100/125], Loss: 0.0314\n",
            "Epoch [85/100], Step [110/125], Loss: 0.0274\n",
            "Epoch [85/100], Step [120/125], Loss: 0.0364\n",
            "Epoch [86/100], Step [10/125], Loss: 0.0476\n",
            "Epoch [86/100], Step [20/125], Loss: 0.0358\n",
            "Epoch [86/100], Step [30/125], Loss: 0.0312\n",
            "Epoch [86/100], Step [40/125], Loss: 0.0292\n",
            "Epoch [86/100], Step [50/125], Loss: 0.0287\n",
            "Epoch [86/100], Step [60/125], Loss: 0.0307\n",
            "Epoch [86/100], Step [70/125], Loss: 0.0206\n",
            "Epoch [86/100], Step [80/125], Loss: 0.0320\n",
            "Epoch [86/100], Step [90/125], Loss: 0.0181\n",
            "Epoch [86/100], Step [100/125], Loss: 0.0198\n",
            "Epoch [86/100], Step [110/125], Loss: 0.0172\n",
            "Epoch [86/100], Step [120/125], Loss: 0.0163\n",
            "Epoch [87/100], Step [10/125], Loss: 0.0235\n",
            "Epoch [87/100], Step [20/125], Loss: 0.0217\n",
            "Epoch [87/100], Step [30/125], Loss: 0.0197\n",
            "Epoch [87/100], Step [40/125], Loss: 0.0198\n",
            "Epoch [87/100], Step [50/125], Loss: 0.0166\n",
            "Epoch [87/100], Step [60/125], Loss: 0.0176\n",
            "Epoch [87/100], Step [70/125], Loss: 0.0138\n",
            "Epoch [87/100], Step [80/125], Loss: 0.0254\n",
            "Epoch [87/100], Step [90/125], Loss: 0.0132\n",
            "Epoch [87/100], Step [100/125], Loss: 0.0126\n",
            "Epoch [87/100], Step [110/125], Loss: 0.0109\n",
            "Epoch [87/100], Step [120/125], Loss: 0.0120\n",
            "Epoch [88/100], Step [10/125], Loss: 0.0153\n",
            "Epoch [88/100], Step [20/125], Loss: 0.0140\n",
            "Epoch [88/100], Step [30/125], Loss: 0.0142\n",
            "Epoch [88/100], Step [40/125], Loss: 0.0149\n",
            "Epoch [88/100], Step [50/125], Loss: 0.0132\n",
            "Epoch [88/100], Step [60/125], Loss: 0.0139\n",
            "Epoch [88/100], Step [70/125], Loss: 0.0106\n",
            "Epoch [88/100], Step [80/125], Loss: 0.0148\n",
            "Epoch [88/100], Step [90/125], Loss: 0.0105\n",
            "Epoch [88/100], Step [100/125], Loss: 0.0101\n",
            "Epoch [88/100], Step [110/125], Loss: 0.0090\n",
            "Epoch [88/100], Step [120/125], Loss: 0.0096\n",
            "Epoch [89/100], Step [10/125], Loss: 0.0125\n",
            "Epoch [89/100], Step [20/125], Loss: 0.0115\n",
            "Epoch [89/100], Step [30/125], Loss: 0.0117\n",
            "Epoch [89/100], Step [40/125], Loss: 0.0117\n",
            "Epoch [89/100], Step [50/125], Loss: 0.0106\n",
            "Epoch [89/100], Step [60/125], Loss: 0.0116\n",
            "Epoch [89/100], Step [70/125], Loss: 0.0088\n",
            "Epoch [89/100], Step [80/125], Loss: 0.0114\n",
            "Epoch [89/100], Step [90/125], Loss: 0.0090\n",
            "Epoch [89/100], Step [100/125], Loss: 0.0087\n",
            "Epoch [89/100], Step [110/125], Loss: 0.0078\n",
            "Epoch [89/100], Step [120/125], Loss: 0.0082\n",
            "Epoch [90/100], Step [10/125], Loss: 0.0106\n",
            "Epoch [90/100], Step [20/125], Loss: 0.0099\n",
            "Epoch [90/100], Step [30/125], Loss: 0.0101\n",
            "Epoch [90/100], Step [40/125], Loss: 0.0100\n",
            "Epoch [90/100], Step [50/125], Loss: 0.0093\n",
            "Epoch [90/100], Step [60/125], Loss: 0.0100\n",
            "Epoch [90/100], Step [70/125], Loss: 0.0077\n",
            "Epoch [90/100], Step [80/125], Loss: 0.0100\n",
            "Epoch [90/100], Step [90/125], Loss: 0.0079\n",
            "Epoch [90/100], Step [100/125], Loss: 0.0077\n",
            "Epoch [90/100], Step [110/125], Loss: 0.0069\n",
            "Epoch [90/100], Step [120/125], Loss: 0.0073\n",
            "Epoch [91/100], Step [10/125], Loss: 0.0093\n",
            "Epoch [91/100], Step [20/125], Loss: 0.0088\n",
            "Epoch [91/100], Step [30/125], Loss: 0.0090\n",
            "Epoch [91/100], Step [40/125], Loss: 0.0089\n",
            "Epoch [91/100], Step [50/125], Loss: 0.0083\n",
            "Epoch [91/100], Step [60/125], Loss: 0.0088\n",
            "Epoch [91/100], Step [70/125], Loss: 0.0069\n",
            "Epoch [91/100], Step [80/125], Loss: 0.0090\n",
            "Epoch [91/100], Step [90/125], Loss: 0.0070\n",
            "Epoch [91/100], Step [100/125], Loss: 0.0069\n",
            "Epoch [91/100], Step [110/125], Loss: 0.0062\n",
            "Epoch [91/100], Step [120/125], Loss: 0.0065\n",
            "Epoch [92/100], Step [10/125], Loss: 0.0084\n",
            "Epoch [92/100], Step [20/125], Loss: 0.0080\n",
            "Epoch [92/100], Step [30/125], Loss: 0.0081\n",
            "Epoch [92/100], Step [40/125], Loss: 0.0080\n",
            "Epoch [92/100], Step [50/125], Loss: 0.0075\n",
            "Epoch [92/100], Step [60/125], Loss: 0.0079\n",
            "Epoch [92/100], Step [70/125], Loss: 0.0062\n",
            "Epoch [92/100], Step [80/125], Loss: 0.0081\n",
            "Epoch [92/100], Step [90/125], Loss: 0.0063\n",
            "Epoch [92/100], Step [100/125], Loss: 0.0062\n",
            "Epoch [92/100], Step [110/125], Loss: 0.0057\n",
            "Epoch [92/100], Step [120/125], Loss: 0.0059\n",
            "Epoch [93/100], Step [10/125], Loss: 0.0075\n",
            "Epoch [93/100], Step [20/125], Loss: 0.0073\n",
            "Epoch [93/100], Step [30/125], Loss: 0.0074\n",
            "Epoch [93/100], Step [40/125], Loss: 0.0073\n",
            "Epoch [93/100], Step [50/125], Loss: 0.0068\n",
            "Epoch [93/100], Step [60/125], Loss: 0.0071\n",
            "Epoch [93/100], Step [70/125], Loss: 0.0057\n",
            "Epoch [93/100], Step [80/125], Loss: 0.0073\n",
            "Epoch [93/100], Step [90/125], Loss: 0.0058\n",
            "Epoch [93/100], Step [100/125], Loss: 0.0057\n",
            "Epoch [93/100], Step [110/125], Loss: 0.0052\n",
            "Epoch [93/100], Step [120/125], Loss: 0.0054\n",
            "Epoch [94/100], Step [10/125], Loss: 0.0068\n",
            "Epoch [94/100], Step [20/125], Loss: 0.0066\n",
            "Epoch [94/100], Step [30/125], Loss: 0.0067\n",
            "Epoch [94/100], Step [40/125], Loss: 0.0067\n",
            "Epoch [94/100], Step [50/125], Loss: 0.0062\n",
            "Epoch [94/100], Step [60/125], Loss: 0.0065\n",
            "Epoch [94/100], Step [70/125], Loss: 0.0052\n",
            "Epoch [94/100], Step [80/125], Loss: 0.0067\n",
            "Epoch [94/100], Step [90/125], Loss: 0.0053\n",
            "Epoch [94/100], Step [100/125], Loss: 0.0052\n",
            "Epoch [94/100], Step [110/125], Loss: 0.0048\n",
            "Epoch [94/100], Step [120/125], Loss: 0.0049\n",
            "Epoch [95/100], Step [10/125], Loss: 0.0062\n",
            "Epoch [95/100], Step [20/125], Loss: 0.0061\n",
            "Epoch [95/100], Step [30/125], Loss: 0.0062\n",
            "Epoch [95/100], Step [40/125], Loss: 0.0061\n",
            "Epoch [95/100], Step [50/125], Loss: 0.0057\n",
            "Epoch [95/100], Step [60/125], Loss: 0.0059\n",
            "Epoch [95/100], Step [70/125], Loss: 0.0048\n",
            "Epoch [95/100], Step [80/125], Loss: 0.0062\n",
            "Epoch [95/100], Step [90/125], Loss: 0.0048\n",
            "Epoch [95/100], Step [100/125], Loss: 0.0048\n",
            "Epoch [95/100], Step [110/125], Loss: 0.0044\n",
            "Epoch [95/100], Step [120/125], Loss: 0.0045\n",
            "Epoch [96/100], Step [10/125], Loss: 0.0057\n",
            "Epoch [96/100], Step [20/125], Loss: 0.0056\n",
            "Epoch [96/100], Step [30/125], Loss: 0.0057\n",
            "Epoch [96/100], Step [40/125], Loss: 0.0057\n",
            "Epoch [96/100], Step [50/125], Loss: 0.0052\n",
            "Epoch [96/100], Step [60/125], Loss: 0.0054\n",
            "Epoch [96/100], Step [70/125], Loss: 0.0044\n",
            "Epoch [96/100], Step [80/125], Loss: 0.0057\n",
            "Epoch [96/100], Step [90/125], Loss: 0.0044\n",
            "Epoch [96/100], Step [100/125], Loss: 0.0044\n",
            "Epoch [96/100], Step [110/125], Loss: 0.0041\n",
            "Epoch [96/100], Step [120/125], Loss: 0.0041\n",
            "Epoch [97/100], Step [10/125], Loss: 0.0053\n",
            "Epoch [97/100], Step [20/125], Loss: 0.0052\n",
            "Epoch [97/100], Step [30/125], Loss: 0.0052\n",
            "Epoch [97/100], Step [40/125], Loss: 0.0052\n",
            "Epoch [97/100], Step [50/125], Loss: 0.0048\n",
            "Epoch [97/100], Step [60/125], Loss: 0.0050\n",
            "Epoch [97/100], Step [70/125], Loss: 0.0041\n",
            "Epoch [97/100], Step [80/125], Loss: 0.0053\n",
            "Epoch [97/100], Step [90/125], Loss: 0.0041\n",
            "Epoch [97/100], Step [100/125], Loss: 0.0041\n",
            "Epoch [97/100], Step [110/125], Loss: 0.0038\n",
            "Epoch [97/100], Step [120/125], Loss: 0.0038\n",
            "Epoch [98/100], Step [10/125], Loss: 0.0049\n",
            "Epoch [98/100], Step [20/125], Loss: 0.0049\n",
            "Epoch [98/100], Step [30/125], Loss: 0.0049\n",
            "Epoch [98/100], Step [40/125], Loss: 0.0048\n",
            "Epoch [98/100], Step [50/125], Loss: 0.0045\n",
            "Epoch [98/100], Step [60/125], Loss: 0.0046\n",
            "Epoch [98/100], Step [70/125], Loss: 0.0038\n",
            "Epoch [98/100], Step [80/125], Loss: 0.0049\n",
            "Epoch [98/100], Step [90/125], Loss: 0.0038\n",
            "Epoch [98/100], Step [100/125], Loss: 0.0038\n",
            "Epoch [98/100], Step [110/125], Loss: 0.0035\n",
            "Epoch [98/100], Step [120/125], Loss: 0.0035\n",
            "Epoch [99/100], Step [10/125], Loss: 0.0045\n",
            "Epoch [99/100], Step [20/125], Loss: 0.0045\n",
            "Epoch [99/100], Step [30/125], Loss: 0.0045\n",
            "Epoch [99/100], Step [40/125], Loss: 0.0045\n",
            "Epoch [99/100], Step [50/125], Loss: 0.0042\n",
            "Epoch [99/100], Step [60/125], Loss: 0.0043\n",
            "Epoch [99/100], Step [70/125], Loss: 0.0035\n",
            "Epoch [99/100], Step [80/125], Loss: 0.0045\n",
            "Epoch [99/100], Step [90/125], Loss: 0.0036\n",
            "Epoch [99/100], Step [100/125], Loss: 0.0035\n",
            "Epoch [99/100], Step [110/125], Loss: 0.0033\n",
            "Epoch [99/100], Step [120/125], Loss: 0.0033\n",
            "Epoch [100/100], Step [10/125], Loss: 0.0042\n",
            "Epoch [100/100], Step [20/125], Loss: 0.0042\n",
            "Epoch [100/100], Step [30/125], Loss: 0.0042\n",
            "Epoch [100/100], Step [40/125], Loss: 0.0042\n",
            "Epoch [100/100], Step [50/125], Loss: 0.0039\n",
            "Epoch [100/100], Step [60/125], Loss: 0.0040\n",
            "Epoch [100/100], Step [70/125], Loss: 0.0033\n",
            "Epoch [100/100], Step [80/125], Loss: 0.0042\n",
            "Epoch [100/100], Step [90/125], Loss: 0.0033\n",
            "Epoch [100/100], Step [100/125], Loss: 0.0033\n",
            "Epoch [100/100], Step [110/125], Loss: 0.0031\n",
            "Epoch [100/100], Step [120/125], Loss: 0.0030\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "model = CRNN(imgH=32, nc=3, nclass=37, nh=256)\n",
        "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "train_crnn(model, dataloader, criterion, optimizer, device=device, num_epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y8msY0ijVqW"
      },
      "outputs": [],
      "source": [
        "def predict(im): # predict only one image at a time\n",
        "    im = im.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        im = im.to(device)\n",
        "\n",
        "        out = model(im)\n",
        "        out = out.softmax(2)\n",
        "        out= out.argmax(2)\n",
        "        out= out.permute(1,0)\n",
        "        return out.cpu()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model"
      ],
      "metadata": {
        "id": "8FIGs5hIRlT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(0, 2000)\n",
        "out = predict(images[i])\n",
        "print(\"Predicted :\", label_to_text(out))\n",
        "print(\"real :\", label_to_text(labels[i]))\n",
        "plt.imshow(images[i].permute(1,2,0))"
      ],
      "metadata": {
        "id": "JziR7VM5caYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "305bbb63-cbfc-4484-9792-df9cd4cf9da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted : WARR\n",
            "real : WAR\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a0cea1613d0>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCu-2v08IU8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}